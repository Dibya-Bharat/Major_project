{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a985821-8134-449d-aa98-4532e7da81fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#content_filtering code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89477cfe-47fe-473b-bdfc-454eb19ec58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 recommended places: [['Haridwar' ' Panch Kedar' ' Hemkund Sahib']]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_excel(\"sample_data.xlsx\")\n",
    "\n",
    "# Preprocessing\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for col in [\"state\", \"category\"]:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Split data\n",
    "X = data.drop([\"place1\", \"place2\", \"place3\"], axis=1)\n",
    "y = data[[\"place1\", \"place2\", \"place3\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train model (example using RandomForestClassifier)\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# User input (state, category, rating)\n",
    "user_input_state = \"Uttarakhand\"  # Replace with actual user input\n",
    "user_input_category = \"Religious\"\n",
    "user_input_rating = 4.5\n",
    "\n",
    "# Process user input\n",
    "user_input_encoded = pd.DataFrame({\n",
    "    \"state\": [label_encoders[\"state\"].transform([user_input_state])[0]],\n",
    "    \"category\": [label_encoders[\"category\"].transform([user_input_category])[0]],\n",
    "    \"rating\": [user_input_rating]\n",
    "})\n",
    "\n",
    "# Get recommendations\n",
    "predictions = model.predict(user_input_encoded)\n",
    "\n",
    "print(\"Top 3 recommended places:\", predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c4316a-3512-4d2a-b9c0-bc6be5d92a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Content_filtering_using_tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1a445b93-d425-42c0-b1e3-a40890904d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - dense_77_accuracy: 0.0096 - dense_78_accuracy: 0.0298 - dense_79_accuracy: 0.0256 - loss: 13.4359 - val_dense_77_accuracy: 0.1136 - val_dense_78_accuracy: 0.0767 - val_dense_79_accuracy: 0.1364 - val_loss: 12.5596\n",
      "Epoch 2/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.0978 - dense_78_accuracy: 0.0672 - dense_79_accuracy: 0.1109 - loss: 12.4705 - val_dense_77_accuracy: 0.1420 - val_dense_78_accuracy: 0.0938 - val_dense_79_accuracy: 0.1619 - val_loss: 11.2408\n",
      "Epoch 3/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.0975 - dense_78_accuracy: 0.0662 - dense_79_accuracy: 0.1213 - loss: 11.4205 - val_dense_77_accuracy: 0.1875 - val_dense_78_accuracy: 0.1335 - val_dense_79_accuracy: 0.1932 - val_loss: 9.8574\n",
      "Epoch 4/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.1649 - dense_78_accuracy: 0.0892 - dense_79_accuracy: 0.1648 - loss: 10.1836 - val_dense_77_accuracy: 0.2585 - val_dense_78_accuracy: 0.1506 - val_dense_79_accuracy: 0.2216 - val_loss: 8.9512\n",
      "Epoch 5/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_77_accuracy: 0.1803 - dense_78_accuracy: 0.1029 - dense_79_accuracy: 0.1870 - loss: 9.3615 - val_dense_77_accuracy: 0.2443 - val_dense_78_accuracy: 0.1705 - val_dense_79_accuracy: 0.2500 - val_loss: 8.2188\n",
      "Epoch 6/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.2234 - dense_78_accuracy: 0.1253 - dense_79_accuracy: 0.2212 - loss: 8.5721 - val_dense_77_accuracy: 0.2301 - val_dense_78_accuracy: 0.1676 - val_dense_79_accuracy: 0.2500 - val_loss: 7.6854\n",
      "Epoch 7/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.2148 - dense_78_accuracy: 0.1515 - dense_79_accuracy: 0.1935 - loss: 8.0409 - val_dense_77_accuracy: 0.2528 - val_dense_78_accuracy: 0.1676 - val_dense_79_accuracy: 0.2585 - val_loss: 7.3061\n",
      "Epoch 8/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.2579 - dense_78_accuracy: 0.1215 - dense_79_accuracy: 0.2287 - loss: 7.5482 - val_dense_77_accuracy: 0.2784 - val_dense_78_accuracy: 0.1790 - val_dense_79_accuracy: 0.2443 - val_loss: 7.0667\n",
      "Epoch 9/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.2682 - dense_78_accuracy: 0.1480 - dense_79_accuracy: 0.1817 - loss: 7.4495 - val_dense_77_accuracy: 0.2614 - val_dense_78_accuracy: 0.1761 - val_dense_79_accuracy: 0.2585 - val_loss: 6.9566\n",
      "Epoch 10/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.2561 - dense_78_accuracy: 0.1340 - dense_79_accuracy: 0.2380 - loss: 7.2107 - val_dense_77_accuracy: 0.2415 - val_dense_78_accuracy: 0.1676 - val_dense_79_accuracy: 0.2557 - val_loss: 6.8186\n",
      "Epoch 11/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.2484 - dense_78_accuracy: 0.1667 - dense_79_accuracy: 0.2521 - loss: 6.9799 - val_dense_77_accuracy: 0.2699 - val_dense_78_accuracy: 0.1562 - val_dense_79_accuracy: 0.2614 - val_loss: 6.7661\n",
      "Epoch 12/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.3195 - dense_78_accuracy: 0.1658 - dense_79_accuracy: 0.2878 - loss: 6.8355 - val_dense_77_accuracy: 0.2557 - val_dense_78_accuracy: 0.1676 - val_dense_79_accuracy: 0.2500 - val_loss: 6.6348\n",
      "Epoch 13/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_77_accuracy: 0.3091 - dense_78_accuracy: 0.1775 - dense_79_accuracy: 0.2831 - loss: 6.7144 - val_dense_77_accuracy: 0.2415 - val_dense_78_accuracy: 0.1989 - val_dense_79_accuracy: 0.2443 - val_loss: 6.5841\n",
      "Epoch 14/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.3246 - dense_78_accuracy: 0.1786 - dense_79_accuracy: 0.2939 - loss: 6.4368 - val_dense_77_accuracy: 0.2415 - val_dense_78_accuracy: 0.1619 - val_dense_79_accuracy: 0.2784 - val_loss: 6.4888\n",
      "Epoch 15/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_77_accuracy: 0.3160 - dense_78_accuracy: 0.1900 - dense_79_accuracy: 0.2861 - loss: 6.4143 - val_dense_77_accuracy: 0.2614 - val_dense_78_accuracy: 0.1932 - val_dense_79_accuracy: 0.2614 - val_loss: 6.4492\n",
      "Epoch 16/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.3059 - dense_78_accuracy: 0.1992 - dense_79_accuracy: 0.2945 - loss: 6.2149 - val_dense_77_accuracy: 0.2727 - val_dense_78_accuracy: 0.1733 - val_dense_79_accuracy: 0.2614 - val_loss: 6.3376\n",
      "Epoch 17/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.3270 - dense_78_accuracy: 0.1789 - dense_79_accuracy: 0.3082 - loss: 6.1818 - val_dense_77_accuracy: 0.2955 - val_dense_78_accuracy: 0.1761 - val_dense_79_accuracy: 0.2557 - val_loss: 6.2323\n",
      "Epoch 18/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.3457 - dense_78_accuracy: 0.1836 - dense_79_accuracy: 0.3119 - loss: 5.9865 - val_dense_77_accuracy: 0.2926 - val_dense_78_accuracy: 0.1818 - val_dense_79_accuracy: 0.2955 - val_loss: 6.1666\n",
      "Epoch 19/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.3677 - dense_78_accuracy: 0.1980 - dense_79_accuracy: 0.3285 - loss: 5.8632 - val_dense_77_accuracy: 0.2926 - val_dense_78_accuracy: 0.1761 - val_dense_79_accuracy: 0.2784 - val_loss: 6.1432\n",
      "Epoch 20/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.3664 - dense_78_accuracy: 0.2119 - dense_79_accuracy: 0.2967 - loss: 5.8071 - val_dense_77_accuracy: 0.2841 - val_dense_78_accuracy: 0.1875 - val_dense_79_accuracy: 0.3011 - val_loss: 6.0325\n",
      "Epoch 21/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.3486 - dense_78_accuracy: 0.2174 - dense_79_accuracy: 0.3246 - loss: 5.7004 - val_dense_77_accuracy: 0.3125 - val_dense_78_accuracy: 0.1960 - val_dense_79_accuracy: 0.3068 - val_loss: 5.9621\n",
      "Epoch 22/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.3625 - dense_78_accuracy: 0.1969 - dense_79_accuracy: 0.3165 - loss: 5.7892 - val_dense_77_accuracy: 0.3125 - val_dense_78_accuracy: 0.2131 - val_dense_79_accuracy: 0.2898 - val_loss: 5.8798\n",
      "Epoch 23/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.3509 - dense_78_accuracy: 0.1982 - dense_79_accuracy: 0.3162 - loss: 5.6893 - val_dense_77_accuracy: 0.3153 - val_dense_78_accuracy: 0.2216 - val_dense_79_accuracy: 0.3040 - val_loss: 5.8325\n",
      "Epoch 24/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.3611 - dense_78_accuracy: 0.1872 - dense_79_accuracy: 0.3423 - loss: 5.5610 - val_dense_77_accuracy: 0.3239 - val_dense_78_accuracy: 0.2045 - val_dense_79_accuracy: 0.2898 - val_loss: 5.8038\n",
      "Epoch 25/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.4108 - dense_78_accuracy: 0.2351 - dense_79_accuracy: 0.3268 - loss: 5.4540 - val_dense_77_accuracy: 0.2756 - val_dense_78_accuracy: 0.2045 - val_dense_79_accuracy: 0.2869 - val_loss: 5.7375\n",
      "Epoch 26/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.3669 - dense_78_accuracy: 0.2374 - dense_79_accuracy: 0.3497 - loss: 5.4184 - val_dense_77_accuracy: 0.3182 - val_dense_78_accuracy: 0.2159 - val_dense_79_accuracy: 0.2841 - val_loss: 5.7090\n",
      "Epoch 27/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - dense_77_accuracy: 0.3754 - dense_78_accuracy: 0.1827 - dense_79_accuracy: 0.3436 - loss: 5.3912 - val_dense_77_accuracy: 0.3097 - val_dense_78_accuracy: 0.2188 - val_dense_79_accuracy: 0.2983 - val_loss: 5.6573\n",
      "Epoch 28/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.3661 - dense_78_accuracy: 0.2267 - dense_79_accuracy: 0.3366 - loss: 5.3890 - val_dense_77_accuracy: 0.3352 - val_dense_78_accuracy: 0.2131 - val_dense_79_accuracy: 0.3040 - val_loss: 5.6656\n",
      "Epoch 29/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.3999 - dense_78_accuracy: 0.2216 - dense_79_accuracy: 0.3293 - loss: 5.4009 - val_dense_77_accuracy: 0.2869 - val_dense_78_accuracy: 0.2244 - val_dense_79_accuracy: 0.3097 - val_loss: 5.6016\n",
      "Epoch 30/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.3906 - dense_78_accuracy: 0.1991 - dense_79_accuracy: 0.3193 - loss: 5.3116 - val_dense_77_accuracy: 0.2841 - val_dense_78_accuracy: 0.2216 - val_dense_79_accuracy: 0.2983 - val_loss: 5.5900\n",
      "Epoch 31/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.3528 - dense_78_accuracy: 0.2027 - dense_79_accuracy: 0.3092 - loss: 5.3161 - val_dense_77_accuracy: 0.2983 - val_dense_78_accuracy: 0.2188 - val_dense_79_accuracy: 0.3125 - val_loss: 5.5683\n",
      "Epoch 32/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.3575 - dense_78_accuracy: 0.2146 - dense_79_accuracy: 0.3570 - loss: 5.2428 - val_dense_77_accuracy: 0.3210 - val_dense_78_accuracy: 0.1875 - val_dense_79_accuracy: 0.2955 - val_loss: 5.5317\n",
      "Epoch 33/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.3757 - dense_78_accuracy: 0.2361 - dense_79_accuracy: 0.3482 - loss: 5.2429 - val_dense_77_accuracy: 0.3267 - val_dense_78_accuracy: 0.2188 - val_dense_79_accuracy: 0.3125 - val_loss: 5.5041\n",
      "Epoch 34/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.3650 - dense_78_accuracy: 0.2129 - dense_79_accuracy: 0.3208 - loss: 5.3051 - val_dense_77_accuracy: 0.3295 - val_dense_78_accuracy: 0.2131 - val_dense_79_accuracy: 0.3210 - val_loss: 5.5351\n",
      "Epoch 35/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.3891 - dense_78_accuracy: 0.2102 - dense_79_accuracy: 0.3449 - loss: 5.2115 - val_dense_77_accuracy: 0.3125 - val_dense_78_accuracy: 0.2045 - val_dense_79_accuracy: 0.2955 - val_loss: 5.4929\n",
      "Epoch 36/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.3572 - dense_78_accuracy: 0.2107 - dense_79_accuracy: 0.3195 - loss: 5.2393 - val_dense_77_accuracy: 0.3125 - val_dense_78_accuracy: 0.2045 - val_dense_79_accuracy: 0.3125 - val_loss: 5.4498\n",
      "Epoch 37/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.3771 - dense_78_accuracy: 0.2185 - dense_79_accuracy: 0.3403 - loss: 5.2155 - val_dense_77_accuracy: 0.3267 - val_dense_78_accuracy: 0.2244 - val_dense_79_accuracy: 0.3097 - val_loss: 5.4393\n",
      "Epoch 38/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.3869 - dense_78_accuracy: 0.2344 - dense_79_accuracy: 0.3502 - loss: 5.1118 - val_dense_77_accuracy: 0.3125 - val_dense_78_accuracy: 0.2131 - val_dense_79_accuracy: 0.3097 - val_loss: 5.4235\n",
      "Epoch 39/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.3958 - dense_78_accuracy: 0.2120 - dense_79_accuracy: 0.3241 - loss: 5.2154 - val_dense_77_accuracy: 0.3125 - val_dense_78_accuracy: 0.2188 - val_dense_79_accuracy: 0.3153 - val_loss: 5.4031\n",
      "Epoch 40/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.3773 - dense_78_accuracy: 0.2270 - dense_79_accuracy: 0.3360 - loss: 5.2056 - val_dense_77_accuracy: 0.3040 - val_dense_78_accuracy: 0.2159 - val_dense_79_accuracy: 0.2926 - val_loss: 5.4129\n",
      "Epoch 41/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.3560 - dense_78_accuracy: 0.2289 - dense_79_accuracy: 0.3409 - loss: 5.0729 - val_dense_77_accuracy: 0.3295 - val_dense_78_accuracy: 0.2102 - val_dense_79_accuracy: 0.2926 - val_loss: 5.4580\n",
      "Epoch 42/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.4143 - dense_78_accuracy: 0.2177 - dense_79_accuracy: 0.3304 - loss: 5.0842 - val_dense_77_accuracy: 0.3182 - val_dense_78_accuracy: 0.2244 - val_dense_79_accuracy: 0.3295 - val_loss: 5.3492\n",
      "Epoch 43/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.3782 - dense_78_accuracy: 0.2236 - dense_79_accuracy: 0.3403 - loss: 5.0247 - val_dense_77_accuracy: 0.3295 - val_dense_78_accuracy: 0.2074 - val_dense_79_accuracy: 0.2983 - val_loss: 5.3287\n",
      "Epoch 44/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.4006 - dense_78_accuracy: 0.2036 - dense_79_accuracy: 0.3038 - loss: 5.1132 - val_dense_77_accuracy: 0.3324 - val_dense_78_accuracy: 0.2301 - val_dense_79_accuracy: 0.3210 - val_loss: 5.3414\n",
      "Epoch 45/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.3823 - dense_78_accuracy: 0.2413 - dense_79_accuracy: 0.3408 - loss: 5.0916 - val_dense_77_accuracy: 0.3267 - val_dense_78_accuracy: 0.2330 - val_dense_79_accuracy: 0.3182 - val_loss: 5.3180\n",
      "Epoch 46/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.3901 - dense_78_accuracy: 0.2129 - dense_79_accuracy: 0.3480 - loss: 5.0594 - val_dense_77_accuracy: 0.3267 - val_dense_78_accuracy: 0.2159 - val_dense_79_accuracy: 0.3267 - val_loss: 5.3265\n",
      "Epoch 47/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.3865 - dense_78_accuracy: 0.2176 - dense_79_accuracy: 0.3846 - loss: 4.9835 - val_dense_77_accuracy: 0.3182 - val_dense_78_accuracy: 0.2244 - val_dense_79_accuracy: 0.3040 - val_loss: 5.3188\n",
      "Epoch 48/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.4022 - dense_78_accuracy: 0.2122 - dense_79_accuracy: 0.3537 - loss: 5.0476 - val_dense_77_accuracy: 0.3182 - val_dense_78_accuracy: 0.2273 - val_dense_79_accuracy: 0.3125 - val_loss: 5.3048\n",
      "Epoch 49/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.3466 - dense_78_accuracy: 0.2268 - dense_79_accuracy: 0.3538 - loss: 5.0283 - val_dense_77_accuracy: 0.3352 - val_dense_78_accuracy: 0.2216 - val_dense_79_accuracy: 0.2869 - val_loss: 5.3798\n",
      "Epoch 50/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.3990 - dense_78_accuracy: 0.2176 - dense_79_accuracy: 0.3401 - loss: 4.9828 - val_dense_77_accuracy: 0.3182 - val_dense_78_accuracy: 0.1903 - val_dense_79_accuracy: 0.3011 - val_loss: 5.3137\n",
      "Epoch 51/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.3752 - dense_78_accuracy: 0.2171 - dense_79_accuracy: 0.3355 - loss: 5.0156 - val_dense_77_accuracy: 0.3352 - val_dense_78_accuracy: 0.1989 - val_dense_79_accuracy: 0.2841 - val_loss: 5.3166\n",
      "Epoch 52/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.3846 - dense_78_accuracy: 0.2251 - dense_79_accuracy: 0.3412 - loss: 4.9850 - val_dense_77_accuracy: 0.3097 - val_dense_78_accuracy: 0.2188 - val_dense_79_accuracy: 0.3125 - val_loss: 5.3004\n",
      "Epoch 53/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.3729 - dense_78_accuracy: 0.2376 - dense_79_accuracy: 0.3412 - loss: 5.0091 - val_dense_77_accuracy: 0.3409 - val_dense_78_accuracy: 0.2131 - val_dense_79_accuracy: 0.3068 - val_loss: 5.2364\n",
      "Epoch 54/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.3943 - dense_78_accuracy: 0.2356 - dense_79_accuracy: 0.3235 - loss: 4.9728 - val_dense_77_accuracy: 0.3381 - val_dense_78_accuracy: 0.2301 - val_dense_79_accuracy: 0.3182 - val_loss: 5.2390\n",
      "Epoch 55/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.4120 - dense_78_accuracy: 0.2132 - dense_79_accuracy: 0.3503 - loss: 4.9405 - val_dense_77_accuracy: 0.2955 - val_dense_78_accuracy: 0.2273 - val_dense_79_accuracy: 0.3381 - val_loss: 5.2793\n",
      "Epoch 56/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.3998 - dense_78_accuracy: 0.2311 - dense_79_accuracy: 0.3557 - loss: 4.9823 - val_dense_77_accuracy: 0.3267 - val_dense_78_accuracy: 0.2244 - val_dense_79_accuracy: 0.3352 - val_loss: 5.2580\n",
      "Epoch 57/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.3836 - dense_78_accuracy: 0.2311 - dense_79_accuracy: 0.3629 - loss: 4.9847 - val_dense_77_accuracy: 0.3409 - val_dense_78_accuracy: 0.2188 - val_dense_79_accuracy: 0.3125 - val_loss: 5.2402\n",
      "Epoch 58/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.3669 - dense_78_accuracy: 0.2264 - dense_79_accuracy: 0.3530 - loss: 4.9957 - val_dense_77_accuracy: 0.3125 - val_dense_78_accuracy: 0.2358 - val_dense_79_accuracy: 0.3182 - val_loss: 5.2239\n",
      "Epoch 59/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.4000 - dense_78_accuracy: 0.2426 - dense_79_accuracy: 0.3445 - loss: 4.9421 - val_dense_77_accuracy: 0.3466 - val_dense_78_accuracy: 0.2273 - val_dense_79_accuracy: 0.3011 - val_loss: 5.2141\n",
      "Epoch 60/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.4002 - dense_78_accuracy: 0.2034 - dense_79_accuracy: 0.3463 - loss: 4.9405 - val_dense_77_accuracy: 0.3352 - val_dense_78_accuracy: 0.2273 - val_dense_79_accuracy: 0.3182 - val_loss: 5.2529\n",
      "Epoch 61/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.3879 - dense_78_accuracy: 0.2267 - dense_79_accuracy: 0.3483 - loss: 4.8701 - val_dense_77_accuracy: 0.3438 - val_dense_78_accuracy: 0.2244 - val_dense_79_accuracy: 0.2784 - val_loss: 5.2160\n",
      "Epoch 62/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.3867 - dense_78_accuracy: 0.2244 - dense_79_accuracy: 0.3352 - loss: 4.9304 - val_dense_77_accuracy: 0.3409 - val_dense_78_accuracy: 0.2045 - val_dense_79_accuracy: 0.3210 - val_loss: 5.2276\n",
      "Epoch 63/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.4207 - dense_78_accuracy: 0.2003 - dense_79_accuracy: 0.3407 - loss: 4.9215 - val_dense_77_accuracy: 0.3466 - val_dense_78_accuracy: 0.2358 - val_dense_79_accuracy: 0.3381 - val_loss: 5.1959\n",
      "Epoch 64/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.4002 - dense_78_accuracy: 0.2196 - dense_79_accuracy: 0.3388 - loss: 4.9975 - val_dense_77_accuracy: 0.3409 - val_dense_78_accuracy: 0.2301 - val_dense_79_accuracy: 0.3381 - val_loss: 5.1758\n",
      "Epoch 65/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.3913 - dense_78_accuracy: 0.2265 - dense_79_accuracy: 0.3551 - loss: 4.9386 - val_dense_77_accuracy: 0.3381 - val_dense_78_accuracy: 0.2330 - val_dense_79_accuracy: 0.3153 - val_loss: 5.2136\n",
      "Epoch 66/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.3919 - dense_78_accuracy: 0.2293 - dense_79_accuracy: 0.3198 - loss: 4.8867 - val_dense_77_accuracy: 0.3153 - val_dense_78_accuracy: 0.2273 - val_dense_79_accuracy: 0.3153 - val_loss: 5.1839\n",
      "Epoch 67/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.3855 - dense_78_accuracy: 0.2469 - dense_79_accuracy: 0.3438 - loss: 4.9024 - val_dense_77_accuracy: 0.3523 - val_dense_78_accuracy: 0.2358 - val_dense_79_accuracy: 0.3267 - val_loss: 5.1487\n",
      "Epoch 68/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.3818 - dense_78_accuracy: 0.2421 - dense_79_accuracy: 0.3527 - loss: 4.8933 - val_dense_77_accuracy: 0.3352 - val_dense_78_accuracy: 0.2301 - val_dense_79_accuracy: 0.3381 - val_loss: 5.2011\n",
      "Epoch 69/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.3699 - dense_78_accuracy: 0.2270 - dense_79_accuracy: 0.3559 - loss: 4.8879 - val_dense_77_accuracy: 0.3381 - val_dense_78_accuracy: 0.2102 - val_dense_79_accuracy: 0.2983 - val_loss: 5.2062\n",
      "Epoch 70/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - dense_77_accuracy: 0.3973 - dense_78_accuracy: 0.2058 - dense_79_accuracy: 0.3538 - loss: 4.8728 - val_dense_77_accuracy: 0.3352 - val_dense_78_accuracy: 0.2358 - val_dense_79_accuracy: 0.3011 - val_loss: 5.1608\n",
      "Epoch 71/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.4012 - dense_78_accuracy: 0.2165 - dense_79_accuracy: 0.3517 - loss: 4.9358 - val_dense_77_accuracy: 0.3352 - val_dense_78_accuracy: 0.2415 - val_dense_79_accuracy: 0.3068 - val_loss: 5.1652\n",
      "Epoch 72/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.3823 - dense_78_accuracy: 0.2403 - dense_79_accuracy: 0.3455 - loss: 4.9344 - val_dense_77_accuracy: 0.3608 - val_dense_78_accuracy: 0.2358 - val_dense_79_accuracy: 0.3153 - val_loss: 5.1461\n",
      "Epoch 73/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.4151 - dense_78_accuracy: 0.2324 - dense_79_accuracy: 0.3505 - loss: 4.8875 - val_dense_77_accuracy: 0.3381 - val_dense_78_accuracy: 0.2045 - val_dense_79_accuracy: 0.3210 - val_loss: 5.1669\n",
      "Epoch 74/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.3780 - dense_78_accuracy: 0.2298 - dense_79_accuracy: 0.3635 - loss: 4.8763 - val_dense_77_accuracy: 0.3494 - val_dense_78_accuracy: 0.2330 - val_dense_79_accuracy: 0.3295 - val_loss: 5.1644\n",
      "Epoch 75/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.3996 - dense_78_accuracy: 0.2231 - dense_79_accuracy: 0.3281 - loss: 4.8517 - val_dense_77_accuracy: 0.3636 - val_dense_78_accuracy: 0.2159 - val_dense_79_accuracy: 0.3409 - val_loss: 5.1465\n",
      "Epoch 76/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.4212 - dense_78_accuracy: 0.2436 - dense_79_accuracy: 0.3528 - loss: 4.8698 - val_dense_77_accuracy: 0.3210 - val_dense_78_accuracy: 0.2330 - val_dense_79_accuracy: 0.3409 - val_loss: 5.1417\n",
      "Epoch 77/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - dense_77_accuracy: 0.3396 - dense_78_accuracy: 0.2360 - dense_79_accuracy: 0.3397 - loss: 4.8935 - val_dense_77_accuracy: 0.3494 - val_dense_78_accuracy: 0.2301 - val_dense_79_accuracy: 0.3438 - val_loss: 5.1649\n",
      "Epoch 78/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.3861 - dense_78_accuracy: 0.2144 - dense_79_accuracy: 0.3728 - loss: 4.8991 - val_dense_77_accuracy: 0.3381 - val_dense_78_accuracy: 0.2386 - val_dense_79_accuracy: 0.3153 - val_loss: 5.1268\n",
      "Epoch 79/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.4164 - dense_78_accuracy: 0.2485 - dense_79_accuracy: 0.3539 - loss: 4.8556 - val_dense_77_accuracy: 0.3523 - val_dense_78_accuracy: 0.2216 - val_dense_79_accuracy: 0.3409 - val_loss: 5.1394\n",
      "Epoch 80/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.3767 - dense_78_accuracy: 0.2337 - dense_79_accuracy: 0.3505 - loss: 4.9072 - val_dense_77_accuracy: 0.3267 - val_dense_78_accuracy: 0.2358 - val_dense_79_accuracy: 0.3381 - val_loss: 5.1300\n",
      "Epoch 81/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.3776 - dense_78_accuracy: 0.2333 - dense_79_accuracy: 0.3814 - loss: 4.8438 - val_dense_77_accuracy: 0.3352 - val_dense_78_accuracy: 0.2386 - val_dense_79_accuracy: 0.3438 - val_loss: 5.1312\n",
      "Epoch 82/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.4128 - dense_78_accuracy: 0.2419 - dense_79_accuracy: 0.3794 - loss: 4.8325 - val_dense_77_accuracy: 0.3409 - val_dense_78_accuracy: 0.2415 - val_dense_79_accuracy: 0.3182 - val_loss: 5.1153\n",
      "Epoch 83/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - dense_77_accuracy: 0.4029 - dense_78_accuracy: 0.2239 - dense_79_accuracy: 0.3391 - loss: 4.8667 - val_dense_77_accuracy: 0.3267 - val_dense_78_accuracy: 0.2386 - val_dense_79_accuracy: 0.3324 - val_loss: 5.1291\n",
      "Epoch 84/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.3798 - dense_78_accuracy: 0.2492 - dense_79_accuracy: 0.3744 - loss: 4.8031 - val_dense_77_accuracy: 0.3381 - val_dense_78_accuracy: 0.2358 - val_dense_79_accuracy: 0.3324 - val_loss: 5.1065\n",
      "Epoch 85/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.4142 - dense_78_accuracy: 0.2471 - dense_79_accuracy: 0.3616 - loss: 4.8230 - val_dense_77_accuracy: 0.3381 - val_dense_78_accuracy: 0.2358 - val_dense_79_accuracy: 0.3324 - val_loss: 5.1060\n",
      "Epoch 86/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_77_accuracy: 0.3922 - dense_78_accuracy: 0.2248 - dense_79_accuracy: 0.3579 - loss: 4.8057 - val_dense_77_accuracy: 0.3494 - val_dense_78_accuracy: 0.2131 - val_dense_79_accuracy: 0.3438 - val_loss: 5.1097\n",
      "Epoch 87/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.4060 - dense_78_accuracy: 0.2459 - dense_79_accuracy: 0.3631 - loss: 4.8139 - val_dense_77_accuracy: 0.3210 - val_dense_78_accuracy: 0.2131 - val_dense_79_accuracy: 0.3182 - val_loss: 5.1157\n",
      "Epoch 88/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - dense_77_accuracy: 0.3851 - dense_78_accuracy: 0.2664 - dense_79_accuracy: 0.3597 - loss: 4.8341 - val_dense_77_accuracy: 0.3295 - val_dense_78_accuracy: 0.2415 - val_dense_79_accuracy: 0.3295 - val_loss: 5.1159\n",
      "Epoch 89/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - dense_77_accuracy: 0.3751 - dense_78_accuracy: 0.2259 - dense_79_accuracy: 0.3522 - loss: 4.8498 - val_dense_77_accuracy: 0.3409 - val_dense_78_accuracy: 0.2159 - val_dense_79_accuracy: 0.3040 - val_loss: 5.1362\n",
      "Epoch 90/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.4081 - dense_78_accuracy: 0.2470 - dense_79_accuracy: 0.3303 - loss: 4.8602 - val_dense_77_accuracy: 0.3523 - val_dense_78_accuracy: 0.2102 - val_dense_79_accuracy: 0.3381 - val_loss: 5.0943\n",
      "Epoch 91/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.3690 - dense_78_accuracy: 0.2371 - dense_79_accuracy: 0.3774 - loss: 4.8074 - val_dense_77_accuracy: 0.3409 - val_dense_78_accuracy: 0.1960 - val_dense_79_accuracy: 0.3040 - val_loss: 5.1373\n",
      "Epoch 92/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.4218 - dense_78_accuracy: 0.2237 - dense_79_accuracy: 0.3325 - loss: 4.8958 - val_dense_77_accuracy: 0.3381 - val_dense_78_accuracy: 0.2386 - val_dense_79_accuracy: 0.3409 - val_loss: 5.0955\n",
      "Epoch 93/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.3752 - dense_78_accuracy: 0.2347 - dense_79_accuracy: 0.3577 - loss: 4.8261 - val_dense_77_accuracy: 0.3523 - val_dense_78_accuracy: 0.2358 - val_dense_79_accuracy: 0.3068 - val_loss: 5.1301\n",
      "Epoch 94/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_77_accuracy: 0.3999 - dense_78_accuracy: 0.2335 - dense_79_accuracy: 0.3212 - loss: 4.8665 - val_dense_77_accuracy: 0.3523 - val_dense_78_accuracy: 0.2330 - val_dense_79_accuracy: 0.3409 - val_loss: 5.1094\n",
      "Epoch 95/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.4334 - dense_78_accuracy: 0.2428 - dense_79_accuracy: 0.3349 - loss: 4.8647 - val_dense_77_accuracy: 0.3324 - val_dense_78_accuracy: 0.2358 - val_dense_79_accuracy: 0.3438 - val_loss: 5.0786\n",
      "Epoch 96/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.3911 - dense_78_accuracy: 0.2238 - dense_79_accuracy: 0.3646 - loss: 4.8453 - val_dense_77_accuracy: 0.3523 - val_dense_78_accuracy: 0.2358 - val_dense_79_accuracy: 0.3267 - val_loss: 5.0800\n",
      "Epoch 97/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.4197 - dense_78_accuracy: 0.2071 - dense_79_accuracy: 0.3498 - loss: 4.8266 - val_dense_77_accuracy: 0.3523 - val_dense_78_accuracy: 0.2330 - val_dense_79_accuracy: 0.3409 - val_loss: 5.0826\n",
      "Epoch 98/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - dense_77_accuracy: 0.4013 - dense_78_accuracy: 0.2289 - dense_79_accuracy: 0.3668 - loss: 4.7473 - val_dense_77_accuracy: 0.3494 - val_dense_78_accuracy: 0.2358 - val_dense_79_accuracy: 0.3438 - val_loss: 5.0781\n",
      "Epoch 99/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - dense_77_accuracy: 0.3947 - dense_78_accuracy: 0.2327 - dense_79_accuracy: 0.3763 - loss: 4.8011 - val_dense_77_accuracy: 0.3523 - val_dense_78_accuracy: 0.2415 - val_dense_79_accuracy: 0.2869 - val_loss: 5.0948\n",
      "Epoch 100/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.4016 - dense_78_accuracy: 0.2487 - dense_79_accuracy: 0.3366 - loss: 4.8177 - val_dense_77_accuracy: 0.3494 - val_dense_78_accuracy: 0.2358 - val_dense_79_accuracy: 0.3381 - val_loss: 5.0866\n",
      "Epoch 101/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.4278 - dense_78_accuracy: 0.2118 - dense_79_accuracy: 0.3617 - loss: 4.7973 - val_dense_77_accuracy: 0.3352 - val_dense_78_accuracy: 0.2386 - val_dense_79_accuracy: 0.3409 - val_loss: 5.0882\n",
      "Epoch 102/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - dense_77_accuracy: 0.3960 - dense_78_accuracy: 0.2356 - dense_79_accuracy: 0.3526 - loss: 4.8011 - val_dense_77_accuracy: 0.3523 - val_dense_78_accuracy: 0.2330 - val_dense_79_accuracy: 0.3438 - val_loss: 5.0664\n",
      "Epoch 103/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - dense_77_accuracy: 0.4150 - dense_78_accuracy: 0.2422 - dense_79_accuracy: 0.3590 - loss: 4.7618 - val_dense_77_accuracy: 0.3381 - val_dense_78_accuracy: 0.2386 - val_dense_79_accuracy: 0.2898 - val_loss: 5.0748\n",
      "Epoch 104/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.3730 - dense_78_accuracy: 0.2428 - dense_79_accuracy: 0.3407 - loss: 4.8105 - val_dense_77_accuracy: 0.3523 - val_dense_78_accuracy: 0.2415 - val_dense_79_accuracy: 0.3352 - val_loss: 5.0674\n",
      "Epoch 105/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.4095 - dense_78_accuracy: 0.2509 - dense_79_accuracy: 0.3664 - loss: 4.8254 - val_dense_77_accuracy: 0.3523 - val_dense_78_accuracy: 0.2386 - val_dense_79_accuracy: 0.3438 - val_loss: 5.0888\n",
      "Epoch 106/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - dense_77_accuracy: 0.4248 - dense_78_accuracy: 0.2330 - dense_79_accuracy: 0.3620 - loss: 4.7652 - val_dense_77_accuracy: 0.3011 - val_dense_78_accuracy: 0.2330 - val_dense_79_accuracy: 0.3011 - val_loss: 5.0745\n",
      "Epoch 107/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.3762 - dense_78_accuracy: 0.2616 - dense_79_accuracy: 0.3608 - loss: 4.7615 - val_dense_77_accuracy: 0.3523 - val_dense_78_accuracy: 0.2386 - val_dense_79_accuracy: 0.3438 - val_loss: 5.0642\n",
      "Epoch 108/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.4062 - dense_78_accuracy: 0.2413 - dense_79_accuracy: 0.3478 - loss: 4.7405 - val_dense_77_accuracy: 0.3381 - val_dense_78_accuracy: 0.2330 - val_dense_79_accuracy: 0.3381 - val_loss: 5.0728\n",
      "Epoch 109/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_77_accuracy: 0.3843 - dense_78_accuracy: 0.2369 - dense_79_accuracy: 0.3716 - loss: 4.7646 - val_dense_77_accuracy: 0.3523 - val_dense_78_accuracy: 0.2074 - val_dense_79_accuracy: 0.3352 - val_loss: 5.0740\n",
      "Epoch 110/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - dense_77_accuracy: 0.3929 - dense_78_accuracy: 0.2153 - dense_79_accuracy: 0.3652 - loss: 4.7986 - val_dense_77_accuracy: 0.3210 - val_dense_78_accuracy: 0.2358 - val_dense_79_accuracy: 0.3324 - val_loss: 5.0820\n",
      "Epoch 111/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - dense_77_accuracy: 0.3945 - dense_78_accuracy: 0.2240 - dense_79_accuracy: 0.3583 - loss: 4.7416 - val_dense_77_accuracy: 0.3295 - val_dense_78_accuracy: 0.2386 - val_dense_79_accuracy: 0.3182 - val_loss: 5.0531\n",
      "Epoch 112/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.3918 - dense_78_accuracy: 0.2425 - dense_79_accuracy: 0.3865 - loss: 4.6963 - val_dense_77_accuracy: 0.3523 - val_dense_78_accuracy: 0.2273 - val_dense_79_accuracy: 0.3381 - val_loss: 5.0507\n",
      "Epoch 113/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.3954 - dense_78_accuracy: 0.2111 - dense_79_accuracy: 0.3693 - loss: 4.7864 - val_dense_77_accuracy: 0.3523 - val_dense_78_accuracy: 0.2358 - val_dense_79_accuracy: 0.3409 - val_loss: 5.0905\n",
      "Epoch 114/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.4109 - dense_78_accuracy: 0.2450 - dense_79_accuracy: 0.3668 - loss: 4.7430 - val_dense_77_accuracy: 0.3267 - val_dense_78_accuracy: 0.2301 - val_dense_79_accuracy: 0.3438 - val_loss: 5.0595\n",
      "Epoch 115/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - dense_77_accuracy: 0.3926 - dense_78_accuracy: 0.2494 - dense_79_accuracy: 0.3686 - loss: 4.7633 - val_dense_77_accuracy: 0.3409 - val_dense_78_accuracy: 0.2188 - val_dense_79_accuracy: 0.3438 - val_loss: 5.0614\n",
      "Epoch 116/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.3698 - dense_78_accuracy: 0.2218 - dense_79_accuracy: 0.3630 - loss: 4.8049 - val_dense_77_accuracy: 0.3523 - val_dense_78_accuracy: 0.2244 - val_dense_79_accuracy: 0.3409 - val_loss: 5.0810\n",
      "Epoch 117/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.4056 - dense_78_accuracy: 0.2522 - dense_79_accuracy: 0.3816 - loss: 4.7392 - val_dense_77_accuracy: 0.3523 - val_dense_78_accuracy: 0.2358 - val_dense_79_accuracy: 0.3295 - val_loss: 5.0537\n",
      "Epoch 118/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.4082 - dense_78_accuracy: 0.2301 - dense_79_accuracy: 0.3406 - loss: 4.8195 - val_dense_77_accuracy: 0.3494 - val_dense_78_accuracy: 0.2074 - val_dense_79_accuracy: 0.3438 - val_loss: 5.0492\n",
      "Epoch 119/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - dense_77_accuracy: 0.3801 - dense_78_accuracy: 0.2552 - dense_79_accuracy: 0.3711 - loss: 4.7955 - val_dense_77_accuracy: 0.3523 - val_dense_78_accuracy: 0.2415 - val_dense_79_accuracy: 0.3210 - val_loss: 5.0461\n",
      "Epoch 120/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.3869 - dense_78_accuracy: 0.2495 - dense_79_accuracy: 0.3594 - loss: 4.8087 - val_dense_77_accuracy: 0.3352 - val_dense_78_accuracy: 0.2131 - val_dense_79_accuracy: 0.3409 - val_loss: 5.0772\n",
      "Epoch 121/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.3976 - dense_78_accuracy: 0.2166 - dense_79_accuracy: 0.3459 - loss: 4.7935 - val_dense_77_accuracy: 0.3494 - val_dense_78_accuracy: 0.2358 - val_dense_79_accuracy: 0.3295 - val_loss: 5.0622\n",
      "Epoch 122/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.4082 - dense_78_accuracy: 0.2281 - dense_79_accuracy: 0.3521 - loss: 4.8049 - val_dense_77_accuracy: 0.3210 - val_dense_78_accuracy: 0.2330 - val_dense_79_accuracy: 0.3381 - val_loss: 5.0530\n",
      "Epoch 123/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.4107 - dense_78_accuracy: 0.2408 - dense_79_accuracy: 0.3616 - loss: 4.7401 - val_dense_77_accuracy: 0.3494 - val_dense_78_accuracy: 0.2131 - val_dense_79_accuracy: 0.3210 - val_loss: 5.0611\n",
      "Epoch 124/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_77_accuracy: 0.3876 - dense_78_accuracy: 0.2372 - dense_79_accuracy: 0.3482 - loss: 4.8634 - val_dense_77_accuracy: 0.3210 - val_dense_78_accuracy: 0.2415 - val_dense_79_accuracy: 0.3068 - val_loss: 5.0637\n",
      "Epoch 125/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.3942 - dense_78_accuracy: 0.2096 - dense_79_accuracy: 0.3600 - loss: 4.6970 - val_dense_77_accuracy: 0.3239 - val_dense_78_accuracy: 0.2273 - val_dense_79_accuracy: 0.3438 - val_loss: 5.0404\n",
      "Epoch 126/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.4052 - dense_78_accuracy: 0.2179 - dense_79_accuracy: 0.3546 - loss: 4.7474 - val_dense_77_accuracy: 0.3523 - val_dense_78_accuracy: 0.2159 - val_dense_79_accuracy: 0.3352 - val_loss: 5.0592\n",
      "Epoch 127/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_77_accuracy: 0.4456 - dense_78_accuracy: 0.2213 - dense_79_accuracy: 0.3555 - loss: 4.8057 - val_dense_77_accuracy: 0.3352 - val_dense_78_accuracy: 0.2415 - val_dense_79_accuracy: 0.3324 - val_loss: 5.0354\n",
      "Epoch 128/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - dense_77_accuracy: 0.3762 - dense_78_accuracy: 0.2518 - dense_79_accuracy: 0.3503 - loss: 4.7661 - val_dense_77_accuracy: 0.3523 - val_dense_78_accuracy: 0.2330 - val_dense_79_accuracy: 0.3438 - val_loss: 5.0602\n",
      "Epoch 129/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_77_accuracy: 0.4153 - dense_78_accuracy: 0.2491 - dense_79_accuracy: 0.3722 - loss: 4.7157 - val_dense_77_accuracy: 0.3295 - val_dense_78_accuracy: 0.2301 - val_dense_79_accuracy: 0.3438 - val_loss: 5.0339\n",
      "Epoch 130/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_77_accuracy: 0.3711 - dense_78_accuracy: 0.2056 - dense_79_accuracy: 0.3739 - loss: 4.8552 - val_dense_77_accuracy: 0.3523 - val_dense_78_accuracy: 0.2386 - val_dense_79_accuracy: 0.3210 - val_loss: 5.0582\n",
      "Epoch 131/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_77_accuracy: 0.4027 - dense_78_accuracy: 0.2522 - dense_79_accuracy: 0.3582 - loss: 4.7344 - val_dense_77_accuracy: 0.3494 - val_dense_78_accuracy: 0.2301 - val_dense_79_accuracy: 0.3381 - val_loss: 5.0238\n",
      "Epoch 132/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - dense_77_accuracy: 0.3937 - dense_78_accuracy: 0.2262 - dense_79_accuracy: 0.3646 - loss: 4.7990 - val_dense_77_accuracy: 0.3523 - val_dense_78_accuracy: 0.2358 - val_dense_79_accuracy: 0.3409 - val_loss: 5.0212\n",
      "Epoch 133/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_77_accuracy: 0.3906 - dense_78_accuracy: 0.2451 - dense_79_accuracy: 0.3628 - loss: 4.7538 - val_dense_77_accuracy: 0.3494 - val_dense_78_accuracy: 0.2216 - val_dense_79_accuracy: 0.2955 - val_loss: 5.0462\n",
      "Epoch 134/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_77_accuracy: 0.4159 - dense_78_accuracy: 0.2131 - dense_79_accuracy: 0.3531 - loss: 4.7337 - val_dense_77_accuracy: 0.3523 - val_dense_78_accuracy: 0.2330 - val_dense_79_accuracy: 0.3438 - val_loss: 5.0447\n",
      "Epoch 135/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.3876 - dense_78_accuracy: 0.2286 - dense_79_accuracy: 0.3527 - loss: 4.7603 - val_dense_77_accuracy: 0.3381 - val_dense_78_accuracy: 0.2386 - val_dense_79_accuracy: 0.3381 - val_loss: 5.0418\n",
      "Epoch 136/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - dense_77_accuracy: 0.4147 - dense_78_accuracy: 0.2539 - dense_79_accuracy: 0.3822 - loss: 4.6698 - val_dense_77_accuracy: 0.3494 - val_dense_78_accuracy: 0.2330 - val_dense_79_accuracy: 0.3409 - val_loss: 5.0222\n",
      "Epoch 137/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_77_accuracy: 0.3964 - dense_78_accuracy: 0.2066 - dense_79_accuracy: 0.3591 - loss: 4.7714 - val_dense_77_accuracy: 0.3523 - val_dense_78_accuracy: 0.2102 - val_dense_79_accuracy: 0.3210 - val_loss: 5.0510\n",
      "Epoch 138/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_77_accuracy: 0.4057 - dense_78_accuracy: 0.2203 - dense_79_accuracy: 0.3725 - loss: 4.7968 - val_dense_77_accuracy: 0.3523 - val_dense_78_accuracy: 0.2386 - val_dense_79_accuracy: 0.3438 - val_loss: 5.0675\n",
      "Epoch 139/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - dense_77_accuracy: 0.4403 - dense_78_accuracy: 0.2268 - dense_79_accuracy: 0.3738 - loss: 4.7552 - val_dense_77_accuracy: 0.3352 - val_dense_78_accuracy: 0.2386 - val_dense_79_accuracy: 0.3267 - val_loss: 5.0374\n",
      "Epoch 140/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - dense_77_accuracy: 0.4167 - dense_78_accuracy: 0.2337 - dense_79_accuracy: 0.3658 - loss: 4.7660 - val_dense_77_accuracy: 0.3523 - val_dense_78_accuracy: 0.2443 - val_dense_79_accuracy: 0.3239 - val_loss: 5.0434\n",
      "Epoch 141/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_77_accuracy: 0.3994 - dense_78_accuracy: 0.2494 - dense_79_accuracy: 0.3695 - loss: 4.7329 - val_dense_77_accuracy: 0.3409 - val_dense_78_accuracy: 0.2358 - val_dense_79_accuracy: 0.3381 - val_loss: 5.0429\n",
      "Epoch 142/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_77_accuracy: 0.4116 - dense_78_accuracy: 0.2125 - dense_79_accuracy: 0.3461 - loss: 4.7324 - val_dense_77_accuracy: 0.3494 - val_dense_78_accuracy: 0.2301 - val_dense_79_accuracy: 0.3324 - val_loss: 5.0319\n",
      "Epoch 143/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - dense_77_accuracy: 0.3900 - dense_78_accuracy: 0.2363 - dense_79_accuracy: 0.3499 - loss: 4.7517 - val_dense_77_accuracy: 0.3182 - val_dense_78_accuracy: 0.2386 - val_dense_79_accuracy: 0.3409 - val_loss: 5.0378\n",
      "Epoch 144/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - dense_77_accuracy: 0.3833 - dense_78_accuracy: 0.2210 - dense_79_accuracy: 0.3672 - loss: 4.7286 - val_dense_77_accuracy: 0.3352 - val_dense_78_accuracy: 0.2415 - val_dense_79_accuracy: 0.3409 - val_loss: 5.0252\n",
      "Epoch 145/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.4113 - dense_78_accuracy: 0.2434 - dense_79_accuracy: 0.3576 - loss: 4.7487 - val_dense_77_accuracy: 0.3523 - val_dense_78_accuracy: 0.2273 - val_dense_79_accuracy: 0.3324 - val_loss: 5.0123\n",
      "Epoch 146/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_77_accuracy: 0.4142 - dense_78_accuracy: 0.2290 - dense_79_accuracy: 0.3563 - loss: 4.7057 - val_dense_77_accuracy: 0.3409 - val_dense_78_accuracy: 0.2358 - val_dense_79_accuracy: 0.3409 - val_loss: 5.0404\n",
      "Epoch 147/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_77_accuracy: 0.3845 - dense_78_accuracy: 0.2392 - dense_79_accuracy: 0.3733 - loss: 4.7379 - val_dense_77_accuracy: 0.3523 - val_dense_78_accuracy: 0.2358 - val_dense_79_accuracy: 0.3409 - val_loss: 5.0122\n",
      "Epoch 148/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_77_accuracy: 0.4132 - dense_78_accuracy: 0.2400 - dense_79_accuracy: 0.3674 - loss: 4.7214 - val_dense_77_accuracy: 0.3494 - val_dense_78_accuracy: 0.2330 - val_dense_79_accuracy: 0.3182 - val_loss: 5.0217\n",
      "Epoch 149/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - dense_77_accuracy: 0.3860 - dense_78_accuracy: 0.2178 - dense_79_accuracy: 0.3477 - loss: 4.7916 - val_dense_77_accuracy: 0.3153 - val_dense_78_accuracy: 0.2358 - val_dense_79_accuracy: 0.3438 - val_loss: 5.0300\n",
      "Epoch 150/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_77_accuracy: 0.4095 - dense_78_accuracy: 0.2403 - dense_79_accuracy: 0.3654 - loss: 4.7031 - val_dense_77_accuracy: 0.3494 - val_dense_78_accuracy: 0.2330 - val_dense_79_accuracy: 0.3438 - val_loss: 5.0222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\h8888\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
      "Recommended places: ('Haldwani', ' Pauri', ' Bhowali')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_excel('sample_data.xlsx')\n",
    "\n",
    "# Initialize label encoders for categorical features and outputs\n",
    "label_encoders = {}\n",
    "for column in ['state', 'category', 'place1', 'place2', 'place3']:\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Normalize the rating column\n",
    "scaler = MinMaxScaler()\n",
    "data['rating'] = scaler.fit_transform(data[['rating']])\n",
    "\n",
    "# Separate features and outputs\n",
    "X = data[['state', 'category', 'rating']].values\n",
    "y1 = data['place1'].values\n",
    "y2 = data['place2'].values\n",
    "y3 = data['place3'].values\n",
    "\n",
    "# Convert outputs to one-hot encoding\n",
    "y1 = tf.keras.utils.to_categorical(y1, num_classes=len(label_encoders['place1'].classes_))\n",
    "y2 = tf.keras.utils.to_categorical(y2, num_classes=len(label_encoders['place2'].classes_))\n",
    "y3 = tf.keras.utils.to_categorical(y3, num_classes=len(label_encoders['place3'].classes_))\n",
    "\n",
    "# Input shape\n",
    "input_shape = X.shape[1]\n",
    "\n",
    "# Define the model\n",
    "input_layer = tf.keras.layers.Input(shape=(input_shape,))\n",
    "dense_layer = tf.keras.layers.Dense(64, activation='relu')(input_layer)\n",
    "dense_layer = tf.keras.layers.Dense(64, activation='relu')(dense_layer)\n",
    "\n",
    "# Output layers for place1, place2, and place3\n",
    "output1 = tf.keras.layers.Dense(len(label_encoders['place1'].classes_), activation='softmax')(dense_layer)\n",
    "output2 = tf.keras.layers.Dense(len(label_encoders['place2'].classes_), activation='softmax')(dense_layer)\n",
    "output3 = tf.keras.layers.Dense(len(label_encoders['place3'].classes_), activation='softmax')(dense_layer)\n",
    "\n",
    "# Create the model\n",
    "model = tf.keras.models.Model(inputs=input_layer, outputs=[output1, output2, output3])\n",
    "\n",
    "# Compile the model with separate metrics for each output\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy', 'accuracy', 'accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, [y1, y2, y3], epochs=150, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Function to preprocess user input\n",
    "def preprocess_input(state, category, rating):\n",
    "    state_encoded = label_encoders['state'].transform([state])\n",
    "    category_encoded = label_encoders['category'].transform([category])\n",
    "    rating_normalized = scaler.transform([[rating]])\n",
    "    return np.array([state_encoded[0], category_encoded[0], rating_normalized[0][0]])\n",
    "\n",
    "# Function to predict and decode recommendations\n",
    "def recommend_places(state, category, rating):\n",
    "    input_data = preprocess_input(state, category, rating)\n",
    "    input_data = np.expand_dims(input_data, axis=0)\n",
    "    predictions = model.predict(input_data)\n",
    "    place1 = label_encoders['place1'].inverse_transform([np.argmax(predictions[0])])[0]\n",
    "    place2 = label_encoders['place2'].inverse_transform([np.argmax(predictions[1])])[0]\n",
    "    place3 = label_encoders['place3'].inverse_transform([np.argmax(predictions[2])])[0]\n",
    "    return place1, place2, place3\n",
    "\n",
    "# Example usage\n",
    "state = 'Uttarakhand'\n",
    "category = 'Hill Station'\n",
    "rating = 4.0\n",
    "recommendations = recommend_places(state, category, rating)\n",
    "print(f'Recommended places: {recommendations}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8bebffd4-b138-4ec4-bc37-65b37ffa3d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - dense_2_accuracy: 0.0141 - dense_3_accuracy: 0.0390 - dense_4_accuracy: 0.0106 - loss: 13.4208 - val_dense_2_accuracy: 0.1023 - val_dense_3_accuracy: 0.0597 - val_dense_4_accuracy: 0.0966 - val_loss: 12.4071\n",
      "Epoch 2/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - dense_2_accuracy: 0.1050 - dense_3_accuracy: 0.0635 - dense_4_accuracy: 0.0873 - loss: 12.2861 - val_dense_2_accuracy: 0.1307 - val_dense_3_accuracy: 0.1335 - val_dense_4_accuracy: 0.1648 - val_loss: 11.1212\n",
      "Epoch 3/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.1515 - dense_3_accuracy: 0.0977 - dense_4_accuracy: 0.1545 - loss: 11.1121 - val_dense_2_accuracy: 0.2131 - val_dense_3_accuracy: 0.1477 - val_dense_4_accuracy: 0.1932 - val_loss: 9.6012\n",
      "Epoch 4/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.2074 - dense_3_accuracy: 0.1204 - dense_4_accuracy: 0.1546 - loss: 9.9379 - val_dense_2_accuracy: 0.2443 - val_dense_3_accuracy: 0.1705 - val_dense_4_accuracy: 0.2443 - val_loss: 8.6374\n",
      "Epoch 5/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.2198 - dense_3_accuracy: 0.1444 - dense_4_accuracy: 0.1970 - loss: 8.8054 - val_dense_2_accuracy: 0.2443 - val_dense_3_accuracy: 0.1705 - val_dense_4_accuracy: 0.2500 - val_loss: 7.9613\n",
      "Epoch 6/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.2256 - dense_3_accuracy: 0.1449 - dense_4_accuracy: 0.2042 - loss: 8.2719 - val_dense_2_accuracy: 0.2500 - val_dense_3_accuracy: 0.1676 - val_dense_4_accuracy: 0.2500 - val_loss: 7.5176\n",
      "Epoch 7/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - dense_2_accuracy: 0.2474 - dense_3_accuracy: 0.1189 - dense_4_accuracy: 0.2363 - loss: 7.7941 - val_dense_2_accuracy: 0.2415 - val_dense_3_accuracy: 0.1477 - val_dense_4_accuracy: 0.2585 - val_loss: 7.2394\n",
      "Epoch 8/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - dense_2_accuracy: 0.2428 - dense_3_accuracy: 0.1338 - dense_4_accuracy: 0.2250 - loss: 7.5655 - val_dense_2_accuracy: 0.2273 - val_dense_3_accuracy: 0.1705 - val_dense_4_accuracy: 0.2500 - val_loss: 7.0519\n",
      "Epoch 9/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.2468 - dense_3_accuracy: 0.1453 - dense_4_accuracy: 0.2429 - loss: 7.3206 - val_dense_2_accuracy: 0.2528 - val_dense_3_accuracy: 0.1847 - val_dense_4_accuracy: 0.2756 - val_loss: 6.8643\n",
      "Epoch 10/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.2945 - dense_3_accuracy: 0.1406 - dense_4_accuracy: 0.2570 - loss: 7.0591 - val_dense_2_accuracy: 0.2557 - val_dense_3_accuracy: 0.1705 - val_dense_4_accuracy: 0.2443 - val_loss: 6.7776\n",
      "Epoch 11/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_2_accuracy: 0.3285 - dense_3_accuracy: 0.1613 - dense_4_accuracy: 0.2891 - loss: 6.7853 - val_dense_2_accuracy: 0.2614 - val_dense_3_accuracy: 0.1562 - val_dense_4_accuracy: 0.2670 - val_loss: 6.6757\n",
      "Epoch 12/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.3112 - dense_3_accuracy: 0.1447 - dense_4_accuracy: 0.2819 - loss: 6.6816 - val_dense_2_accuracy: 0.2585 - val_dense_3_accuracy: 0.1903 - val_dense_4_accuracy: 0.2756 - val_loss: 6.6315\n",
      "Epoch 13/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.3037 - dense_3_accuracy: 0.1900 - dense_4_accuracy: 0.2900 - loss: 6.5133 - val_dense_2_accuracy: 0.2528 - val_dense_3_accuracy: 0.1733 - val_dense_4_accuracy: 0.2443 - val_loss: 6.5394\n",
      "Epoch 14/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - dense_2_accuracy: 0.3484 - dense_3_accuracy: 0.1629 - dense_4_accuracy: 0.2749 - loss: 6.3013 - val_dense_2_accuracy: 0.2415 - val_dense_3_accuracy: 0.1449 - val_dense_4_accuracy: 0.2301 - val_loss: 6.4504\n",
      "Epoch 15/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.3182 - dense_3_accuracy: 0.1754 - dense_4_accuracy: 0.2624 - loss: 6.2798 - val_dense_2_accuracy: 0.2727 - val_dense_3_accuracy: 0.1790 - val_dense_4_accuracy: 0.2756 - val_loss: 6.3352\n",
      "Epoch 16/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.3500 - dense_3_accuracy: 0.1834 - dense_4_accuracy: 0.3177 - loss: 6.1565 - val_dense_2_accuracy: 0.2841 - val_dense_3_accuracy: 0.1790 - val_dense_4_accuracy: 0.2557 - val_loss: 6.2743\n",
      "Epoch 17/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - dense_2_accuracy: 0.3409 - dense_3_accuracy: 0.1858 - dense_4_accuracy: 0.2875 - loss: 6.0288 - val_dense_2_accuracy: 0.3011 - val_dense_3_accuracy: 0.1648 - val_dense_4_accuracy: 0.2756 - val_loss: 6.2425\n",
      "Epoch 18/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.3406 - dense_3_accuracy: 0.1989 - dense_4_accuracy: 0.3032 - loss: 5.9399 - val_dense_2_accuracy: 0.2869 - val_dense_3_accuracy: 0.1960 - val_dense_4_accuracy: 0.2898 - val_loss: 6.1346\n",
      "Epoch 19/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.3588 - dense_3_accuracy: 0.1925 - dense_4_accuracy: 0.2902 - loss: 5.8188 - val_dense_2_accuracy: 0.2557 - val_dense_3_accuracy: 0.2045 - val_dense_4_accuracy: 0.2955 - val_loss: 6.0909\n",
      "Epoch 20/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.3625 - dense_3_accuracy: 0.1915 - dense_4_accuracy: 0.2994 - loss: 5.7001 - val_dense_2_accuracy: 0.2670 - val_dense_3_accuracy: 0.1932 - val_dense_4_accuracy: 0.2955 - val_loss: 5.9890\n",
      "Epoch 21/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.3422 - dense_3_accuracy: 0.2289 - dense_4_accuracy: 0.3019 - loss: 5.6593 - val_dense_2_accuracy: 0.3153 - val_dense_3_accuracy: 0.1818 - val_dense_4_accuracy: 0.2841 - val_loss: 5.9484\n",
      "Epoch 22/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.3725 - dense_3_accuracy: 0.2092 - dense_4_accuracy: 0.2931 - loss: 5.5780 - val_dense_2_accuracy: 0.2812 - val_dense_3_accuracy: 0.2074 - val_dense_4_accuracy: 0.2670 - val_loss: 5.9611\n",
      "Epoch 23/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - dense_2_accuracy: 0.3447 - dense_3_accuracy: 0.2100 - dense_4_accuracy: 0.3125 - loss: 5.5541 - val_dense_2_accuracy: 0.3011 - val_dense_3_accuracy: 0.2102 - val_dense_4_accuracy: 0.3040 - val_loss: 5.8599\n",
      "Epoch 24/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.3767 - dense_3_accuracy: 0.2086 - dense_4_accuracy: 0.2950 - loss: 5.5529 - val_dense_2_accuracy: 0.2983 - val_dense_3_accuracy: 0.1989 - val_dense_4_accuracy: 0.3011 - val_loss: 5.7901\n",
      "Epoch 25/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - dense_2_accuracy: 0.3623 - dense_3_accuracy: 0.1814 - dense_4_accuracy: 0.3336 - loss: 5.5238 - val_dense_2_accuracy: 0.3125 - val_dense_3_accuracy: 0.1818 - val_dense_4_accuracy: 0.3068 - val_loss: 5.7969\n",
      "Epoch 26/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.3861 - dense_3_accuracy: 0.2305 - dense_4_accuracy: 0.3184 - loss: 5.4129 - val_dense_2_accuracy: 0.2983 - val_dense_3_accuracy: 0.1903 - val_dense_4_accuracy: 0.3125 - val_loss: 5.7807\n",
      "Epoch 27/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - dense_2_accuracy: 0.3440 - dense_3_accuracy: 0.2316 - dense_4_accuracy: 0.3534 - loss: 5.4670 - val_dense_2_accuracy: 0.2926 - val_dense_3_accuracy: 0.2188 - val_dense_4_accuracy: 0.3267 - val_loss: 5.7148\n",
      "Epoch 28/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - dense_2_accuracy: 0.3902 - dense_3_accuracy: 0.2095 - dense_4_accuracy: 0.3386 - loss: 5.3345 - val_dense_2_accuracy: 0.3295 - val_dense_3_accuracy: 0.2074 - val_dense_4_accuracy: 0.2955 - val_loss: 5.6493\n",
      "Epoch 29/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.3516 - dense_3_accuracy: 0.2419 - dense_4_accuracy: 0.3538 - loss: 5.2972 - val_dense_2_accuracy: 0.3267 - val_dense_3_accuracy: 0.1932 - val_dense_4_accuracy: 0.2841 - val_loss: 5.6515\n",
      "Epoch 30/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_2_accuracy: 0.3786 - dense_3_accuracy: 0.2353 - dense_4_accuracy: 0.3382 - loss: 5.2495 - val_dense_2_accuracy: 0.3011 - val_dense_3_accuracy: 0.2102 - val_dense_4_accuracy: 0.3040 - val_loss: 5.6306\n",
      "Epoch 31/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_2_accuracy: 0.3664 - dense_3_accuracy: 0.2037 - dense_4_accuracy: 0.3288 - loss: 5.2797 - val_dense_2_accuracy: 0.3153 - val_dense_3_accuracy: 0.2188 - val_dense_4_accuracy: 0.3068 - val_loss: 5.5781\n",
      "Epoch 32/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.3755 - dense_3_accuracy: 0.2291 - dense_4_accuracy: 0.3361 - loss: 5.2237 - val_dense_2_accuracy: 0.3267 - val_dense_3_accuracy: 0.2188 - val_dense_4_accuracy: 0.2983 - val_loss: 5.5349\n",
      "Epoch 33/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.3817 - dense_3_accuracy: 0.2195 - dense_4_accuracy: 0.3363 - loss: 5.2001 - val_dense_2_accuracy: 0.3267 - val_dense_3_accuracy: 0.2159 - val_dense_4_accuracy: 0.2841 - val_loss: 5.5406\n",
      "Epoch 34/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.3978 - dense_3_accuracy: 0.2062 - dense_4_accuracy: 0.3159 - loss: 5.1919 - val_dense_2_accuracy: 0.3324 - val_dense_3_accuracy: 0.2045 - val_dense_4_accuracy: 0.3182 - val_loss: 5.5117\n",
      "Epoch 35/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - dense_2_accuracy: 0.3964 - dense_3_accuracy: 0.2242 - dense_4_accuracy: 0.3407 - loss: 5.1828 - val_dense_2_accuracy: 0.3153 - val_dense_3_accuracy: 0.2188 - val_dense_4_accuracy: 0.3125 - val_loss: 5.4790\n",
      "Epoch 36/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.3598 - dense_3_accuracy: 0.2153 - dense_4_accuracy: 0.3453 - loss: 5.1947 - val_dense_2_accuracy: 0.3381 - val_dense_3_accuracy: 0.2216 - val_dense_4_accuracy: 0.3153 - val_loss: 5.4747\n",
      "Epoch 37/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.3631 - dense_3_accuracy: 0.2086 - dense_4_accuracy: 0.3391 - loss: 5.1981 - val_dense_2_accuracy: 0.2955 - val_dense_3_accuracy: 0.2159 - val_dense_4_accuracy: 0.2727 - val_loss: 5.4576\n",
      "Epoch 38/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_2_accuracy: 0.3393 - dense_3_accuracy: 0.2156 - dense_4_accuracy: 0.3044 - loss: 5.1781 - val_dense_2_accuracy: 0.3011 - val_dense_3_accuracy: 0.2017 - val_dense_4_accuracy: 0.2955 - val_loss: 5.4798\n",
      "Epoch 39/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.3823 - dense_3_accuracy: 0.2161 - dense_4_accuracy: 0.3482 - loss: 5.1294 - val_dense_2_accuracy: 0.2983 - val_dense_3_accuracy: 0.2216 - val_dense_4_accuracy: 0.2869 - val_loss: 5.4416\n",
      "Epoch 40/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.3999 - dense_3_accuracy: 0.2340 - dense_4_accuracy: 0.3392 - loss: 5.1518 - val_dense_2_accuracy: 0.3068 - val_dense_3_accuracy: 0.2131 - val_dense_4_accuracy: 0.3040 - val_loss: 5.4380\n",
      "Epoch 41/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.4012 - dense_3_accuracy: 0.2411 - dense_4_accuracy: 0.3490 - loss: 5.0542 - val_dense_2_accuracy: 0.3324 - val_dense_3_accuracy: 0.1875 - val_dense_4_accuracy: 0.3182 - val_loss: 5.4217\n",
      "Epoch 42/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.3685 - dense_3_accuracy: 0.2123 - dense_4_accuracy: 0.3290 - loss: 5.1519 - val_dense_2_accuracy: 0.3295 - val_dense_3_accuracy: 0.2244 - val_dense_4_accuracy: 0.3324 - val_loss: 5.4056\n",
      "Epoch 43/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_2_accuracy: 0.3771 - dense_3_accuracy: 0.2064 - dense_4_accuracy: 0.3336 - loss: 5.0953 - val_dense_2_accuracy: 0.3097 - val_dense_3_accuracy: 0.2244 - val_dense_4_accuracy: 0.3295 - val_loss: 5.4243\n",
      "Epoch 44/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_2_accuracy: 0.3886 - dense_3_accuracy: 0.1885 - dense_4_accuracy: 0.3538 - loss: 5.0684 - val_dense_2_accuracy: 0.3210 - val_dense_3_accuracy: 0.2216 - val_dense_4_accuracy: 0.3068 - val_loss: 5.4029\n",
      "Epoch 45/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_2_accuracy: 0.3743 - dense_3_accuracy: 0.2369 - dense_4_accuracy: 0.3485 - loss: 5.0468 - val_dense_2_accuracy: 0.3381 - val_dense_3_accuracy: 0.2131 - val_dense_4_accuracy: 0.2756 - val_loss: 5.3619\n",
      "Epoch 46/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_2_accuracy: 0.3959 - dense_3_accuracy: 0.2368 - dense_4_accuracy: 0.3497 - loss: 5.0048 - val_dense_2_accuracy: 0.3210 - val_dense_3_accuracy: 0.2244 - val_dense_4_accuracy: 0.3040 - val_loss: 5.3837\n",
      "Epoch 47/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_2_accuracy: 0.3927 - dense_3_accuracy: 0.2084 - dense_4_accuracy: 0.3748 - loss: 5.0073 - val_dense_2_accuracy: 0.3466 - val_dense_3_accuracy: 0.2244 - val_dense_4_accuracy: 0.3267 - val_loss: 5.3346\n",
      "Epoch 48/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_2_accuracy: 0.4164 - dense_3_accuracy: 0.2216 - dense_4_accuracy: 0.3644 - loss: 4.9812 - val_dense_2_accuracy: 0.3239 - val_dense_3_accuracy: 0.2188 - val_dense_4_accuracy: 0.3153 - val_loss: 5.3403\n",
      "Epoch 49/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - dense_2_accuracy: 0.4120 - dense_3_accuracy: 0.2359 - dense_4_accuracy: 0.3546 - loss: 4.9890 - val_dense_2_accuracy: 0.3295 - val_dense_3_accuracy: 0.2273 - val_dense_4_accuracy: 0.2812 - val_loss: 5.3097\n",
      "Epoch 50/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_2_accuracy: 0.4067 - dense_3_accuracy: 0.2100 - dense_4_accuracy: 0.3279 - loss: 5.0163 - val_dense_2_accuracy: 0.3040 - val_dense_3_accuracy: 0.2273 - val_dense_4_accuracy: 0.2926 - val_loss: 5.3431\n",
      "Epoch 51/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.3630 - dense_3_accuracy: 0.2246 - dense_4_accuracy: 0.3184 - loss: 5.0497 - val_dense_2_accuracy: 0.3466 - val_dense_3_accuracy: 0.2301 - val_dense_4_accuracy: 0.3040 - val_loss: 5.3283\n",
      "Epoch 52/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_2_accuracy: 0.4024 - dense_3_accuracy: 0.2032 - dense_4_accuracy: 0.3296 - loss: 5.0381 - val_dense_2_accuracy: 0.2841 - val_dense_3_accuracy: 0.2301 - val_dense_4_accuracy: 0.2955 - val_loss: 5.3009\n",
      "Epoch 53/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - dense_2_accuracy: 0.3832 - dense_3_accuracy: 0.2187 - dense_4_accuracy: 0.3672 - loss: 4.9276 - val_dense_2_accuracy: 0.3125 - val_dense_3_accuracy: 0.2386 - val_dense_4_accuracy: 0.3239 - val_loss: 5.2711\n",
      "Epoch 54/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_2_accuracy: 0.3957 - dense_3_accuracy: 0.2151 - dense_4_accuracy: 0.3246 - loss: 5.0289 - val_dense_2_accuracy: 0.3040 - val_dense_3_accuracy: 0.2358 - val_dense_4_accuracy: 0.3267 - val_loss: 5.2642\n",
      "Epoch 55/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_2_accuracy: 0.3817 - dense_3_accuracy: 0.2132 - dense_4_accuracy: 0.3356 - loss: 4.9868 - val_dense_2_accuracy: 0.3068 - val_dense_3_accuracy: 0.2273 - val_dense_4_accuracy: 0.3381 - val_loss: 5.2951\n",
      "Epoch 56/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.3889 - dense_3_accuracy: 0.2384 - dense_4_accuracy: 0.3684 - loss: 4.9915 - val_dense_2_accuracy: 0.3125 - val_dense_3_accuracy: 0.2301 - val_dense_4_accuracy: 0.3267 - val_loss: 5.3013\n",
      "Epoch 57/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_2_accuracy: 0.4091 - dense_3_accuracy: 0.2329 - dense_4_accuracy: 0.3539 - loss: 4.8781 - val_dense_2_accuracy: 0.3409 - val_dense_3_accuracy: 0.2244 - val_dense_4_accuracy: 0.3239 - val_loss: 5.2631\n",
      "Epoch 58/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_2_accuracy: 0.3988 - dense_3_accuracy: 0.2340 - dense_4_accuracy: 0.3592 - loss: 4.9331 - val_dense_2_accuracy: 0.3494 - val_dense_3_accuracy: 0.2386 - val_dense_4_accuracy: 0.3068 - val_loss: 5.2393\n",
      "Epoch 59/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_2_accuracy: 0.3898 - dense_3_accuracy: 0.2446 - dense_4_accuracy: 0.3354 - loss: 4.9738 - val_dense_2_accuracy: 0.3182 - val_dense_3_accuracy: 0.2244 - val_dense_4_accuracy: 0.3239 - val_loss: 5.2806\n",
      "Epoch 60/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_2_accuracy: 0.3923 - dense_3_accuracy: 0.2374 - dense_4_accuracy: 0.3588 - loss: 4.9865 - val_dense_2_accuracy: 0.3324 - val_dense_3_accuracy: 0.2330 - val_dense_4_accuracy: 0.3239 - val_loss: 5.2380\n",
      "Epoch 61/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - dense_2_accuracy: 0.4018 - dense_3_accuracy: 0.2063 - dense_4_accuracy: 0.3586 - loss: 4.9624 - val_dense_2_accuracy: 0.3352 - val_dense_3_accuracy: 0.2273 - val_dense_4_accuracy: 0.3267 - val_loss: 5.2618\n",
      "Epoch 62/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.3816 - dense_3_accuracy: 0.2297 - dense_4_accuracy: 0.3449 - loss: 4.9959 - val_dense_2_accuracy: 0.3324 - val_dense_3_accuracy: 0.2330 - val_dense_4_accuracy: 0.3352 - val_loss: 5.2430\n",
      "Epoch 63/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - dense_2_accuracy: 0.3750 - dense_3_accuracy: 0.2271 - dense_4_accuracy: 0.3562 - loss: 4.9358 - val_dense_2_accuracy: 0.3438 - val_dense_3_accuracy: 0.2273 - val_dense_4_accuracy: 0.3267 - val_loss: 5.2193\n",
      "Epoch 64/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - dense_2_accuracy: 0.3867 - dense_3_accuracy: 0.2428 - dense_4_accuracy: 0.3490 - loss: 4.9644 - val_dense_2_accuracy: 0.3466 - val_dense_3_accuracy: 0.2273 - val_dense_4_accuracy: 0.3182 - val_loss: 5.2306\n",
      "Epoch 65/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - dense_2_accuracy: 0.3939 - dense_3_accuracy: 0.1834 - dense_4_accuracy: 0.3475 - loss: 4.9663 - val_dense_2_accuracy: 0.3438 - val_dense_3_accuracy: 0.2358 - val_dense_4_accuracy: 0.3210 - val_loss: 5.2123\n",
      "Epoch 66/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.3657 - dense_3_accuracy: 0.2189 - dense_4_accuracy: 0.3369 - loss: 4.9457 - val_dense_2_accuracy: 0.3494 - val_dense_3_accuracy: 0.2443 - val_dense_4_accuracy: 0.3352 - val_loss: 5.2205\n",
      "Epoch 67/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - dense_2_accuracy: 0.3869 - dense_3_accuracy: 0.2366 - dense_4_accuracy: 0.3737 - loss: 4.8936 - val_dense_2_accuracy: 0.3381 - val_dense_3_accuracy: 0.2188 - val_dense_4_accuracy: 0.3182 - val_loss: 5.2114\n",
      "Epoch 68/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - dense_2_accuracy: 0.3851 - dense_3_accuracy: 0.2577 - dense_4_accuracy: 0.3443 - loss: 4.8157 - val_dense_2_accuracy: 0.3210 - val_dense_3_accuracy: 0.2330 - val_dense_4_accuracy: 0.3381 - val_loss: 5.2143\n",
      "Epoch 69/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - dense_2_accuracy: 0.3910 - dense_3_accuracy: 0.2362 - dense_4_accuracy: 0.3601 - loss: 4.9422 - val_dense_2_accuracy: 0.3381 - val_dense_3_accuracy: 0.2330 - val_dense_4_accuracy: 0.3040 - val_loss: 5.2226\n",
      "Epoch 70/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.3993 - dense_3_accuracy: 0.2394 - dense_4_accuracy: 0.3665 - loss: 4.9383 - val_dense_2_accuracy: 0.3494 - val_dense_3_accuracy: 0.2017 - val_dense_4_accuracy: 0.2756 - val_loss: 5.2254\n",
      "Epoch 71/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - dense_2_accuracy: 0.4115 - dense_3_accuracy: 0.2057 - dense_4_accuracy: 0.3602 - loss: 4.9297 - val_dense_2_accuracy: 0.3409 - val_dense_3_accuracy: 0.2386 - val_dense_4_accuracy: 0.3182 - val_loss: 5.1768\n",
      "Epoch 72/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - dense_2_accuracy: 0.3702 - dense_3_accuracy: 0.2234 - dense_4_accuracy: 0.3570 - loss: 4.9270 - val_dense_2_accuracy: 0.3381 - val_dense_3_accuracy: 0.2386 - val_dense_4_accuracy: 0.3438 - val_loss: 5.1663\n",
      "Epoch 73/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - dense_2_accuracy: 0.3906 - dense_3_accuracy: 0.2182 - dense_4_accuracy: 0.3730 - loss: 4.8638 - val_dense_2_accuracy: 0.3381 - val_dense_3_accuracy: 0.2386 - val_dense_4_accuracy: 0.3267 - val_loss: 5.1582\n",
      "Epoch 74/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - dense_2_accuracy: 0.3908 - dense_3_accuracy: 0.2581 - dense_4_accuracy: 0.3624 - loss: 4.8433 - val_dense_2_accuracy: 0.3267 - val_dense_3_accuracy: 0.2216 - val_dense_4_accuracy: 0.3381 - val_loss: 5.2083\n",
      "Epoch 75/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - dense_2_accuracy: 0.3686 - dense_3_accuracy: 0.2439 - dense_4_accuracy: 0.3373 - loss: 4.9361 - val_dense_2_accuracy: 0.3438 - val_dense_3_accuracy: 0.2244 - val_dense_4_accuracy: 0.3438 - val_loss: 5.1646\n",
      "Epoch 76/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - dense_2_accuracy: 0.3870 - dense_3_accuracy: 0.2175 - dense_4_accuracy: 0.3595 - loss: 4.9413 - val_dense_2_accuracy: 0.3210 - val_dense_3_accuracy: 0.1989 - val_dense_4_accuracy: 0.3210 - val_loss: 5.1695\n",
      "Epoch 77/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.3780 - dense_3_accuracy: 0.2313 - dense_4_accuracy: 0.3577 - loss: 4.8444 - val_dense_2_accuracy: 0.3409 - val_dense_3_accuracy: 0.2017 - val_dense_4_accuracy: 0.3438 - val_loss: 5.1567\n",
      "Epoch 78/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.4020 - dense_3_accuracy: 0.2382 - dense_4_accuracy: 0.3726 - loss: 4.8331 - val_dense_2_accuracy: 0.3494 - val_dense_3_accuracy: 0.2358 - val_dense_4_accuracy: 0.3352 - val_loss: 5.1734\n",
      "Epoch 79/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - dense_2_accuracy: 0.3942 - dense_3_accuracy: 0.2350 - dense_4_accuracy: 0.3641 - loss: 4.8303 - val_dense_2_accuracy: 0.3409 - val_dense_3_accuracy: 0.2443 - val_dense_4_accuracy: 0.3324 - val_loss: 5.1606\n",
      "Epoch 80/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - dense_2_accuracy: 0.3813 - dense_3_accuracy: 0.2451 - dense_4_accuracy: 0.3716 - loss: 4.8712 - val_dense_2_accuracy: 0.3523 - val_dense_3_accuracy: 0.2244 - val_dense_4_accuracy: 0.3438 - val_loss: 5.1734\n",
      "Epoch 81/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - dense_2_accuracy: 0.4261 - dense_3_accuracy: 0.2361 - dense_4_accuracy: 0.3288 - loss: 4.8468 - val_dense_2_accuracy: 0.3352 - val_dense_3_accuracy: 0.2330 - val_dense_4_accuracy: 0.3210 - val_loss: 5.1468\n",
      "Epoch 82/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - dense_2_accuracy: 0.3888 - dense_3_accuracy: 0.2314 - dense_4_accuracy: 0.3625 - loss: 4.8691 - val_dense_2_accuracy: 0.3523 - val_dense_3_accuracy: 0.2273 - val_dense_4_accuracy: 0.3267 - val_loss: 5.1468\n",
      "Epoch 83/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.3738 - dense_3_accuracy: 0.2354 - dense_4_accuracy: 0.3749 - loss: 4.9267 - val_dense_2_accuracy: 0.3352 - val_dense_3_accuracy: 0.2358 - val_dense_4_accuracy: 0.2955 - val_loss: 5.1672\n",
      "Epoch 84/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.3910 - dense_3_accuracy: 0.2588 - dense_4_accuracy: 0.3425 - loss: 4.8672 - val_dense_2_accuracy: 0.3324 - val_dense_3_accuracy: 0.2074 - val_dense_4_accuracy: 0.3068 - val_loss: 5.1310\n",
      "Epoch 85/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.4055 - dense_3_accuracy: 0.2176 - dense_4_accuracy: 0.3546 - loss: 4.8402 - val_dense_2_accuracy: 0.3381 - val_dense_3_accuracy: 0.2301 - val_dense_4_accuracy: 0.2955 - val_loss: 5.1361\n",
      "Epoch 86/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.3948 - dense_3_accuracy: 0.2322 - dense_4_accuracy: 0.3523 - loss: 4.9148 - val_dense_2_accuracy: 0.3210 - val_dense_3_accuracy: 0.2386 - val_dense_4_accuracy: 0.3068 - val_loss: 5.1429\n",
      "Epoch 87/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - dense_2_accuracy: 0.3730 - dense_3_accuracy: 0.2408 - dense_4_accuracy: 0.3519 - loss: 4.8510 - val_dense_2_accuracy: 0.3210 - val_dense_3_accuracy: 0.2386 - val_dense_4_accuracy: 0.3295 - val_loss: 5.1435\n",
      "Epoch 88/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.4064 - dense_3_accuracy: 0.2156 - dense_4_accuracy: 0.3601 - loss: 4.8797 - val_dense_2_accuracy: 0.3239 - val_dense_3_accuracy: 0.2358 - val_dense_4_accuracy: 0.3295 - val_loss: 5.1135\n",
      "Epoch 89/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - dense_2_accuracy: 0.3962 - dense_3_accuracy: 0.2456 - dense_4_accuracy: 0.3540 - loss: 4.7904 - val_dense_2_accuracy: 0.3494 - val_dense_3_accuracy: 0.2386 - val_dense_4_accuracy: 0.3011 - val_loss: 5.1171\n",
      "Epoch 90/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.3936 - dense_3_accuracy: 0.2379 - dense_4_accuracy: 0.3518 - loss: 4.9039 - val_dense_2_accuracy: 0.3324 - val_dense_3_accuracy: 0.2358 - val_dense_4_accuracy: 0.3409 - val_loss: 5.1106\n",
      "Epoch 91/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 0.3924 - dense_3_accuracy: 0.2525 - dense_4_accuracy: 0.3757 - loss: 4.8077 - val_dense_2_accuracy: 0.3409 - val_dense_3_accuracy: 0.2358 - val_dense_4_accuracy: 0.3011 - val_loss: 5.1309\n",
      "Epoch 92/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.4036 - dense_3_accuracy: 0.2169 - dense_4_accuracy: 0.3564 - loss: 4.7994 - val_dense_2_accuracy: 0.3381 - val_dense_3_accuracy: 0.2188 - val_dense_4_accuracy: 0.3352 - val_loss: 5.0941\n",
      "Epoch 93/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.4183 - dense_3_accuracy: 0.2137 - dense_4_accuracy: 0.3600 - loss: 4.8438 - val_dense_2_accuracy: 0.3409 - val_dense_3_accuracy: 0.2301 - val_dense_4_accuracy: 0.3381 - val_loss: 5.1088\n",
      "Epoch 94/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - dense_2_accuracy: 0.3709 - dense_3_accuracy: 0.2087 - dense_4_accuracy: 0.3308 - loss: 4.8717 - val_dense_2_accuracy: 0.3494 - val_dense_3_accuracy: 0.2301 - val_dense_4_accuracy: 0.3409 - val_loss: 5.1172\n",
      "Epoch 95/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - dense_2_accuracy: 0.4112 - dense_3_accuracy: 0.2412 - dense_4_accuracy: 0.3604 - loss: 4.8365 - val_dense_2_accuracy: 0.3381 - val_dense_3_accuracy: 0.2386 - val_dense_4_accuracy: 0.3182 - val_loss: 5.0983\n",
      "Epoch 96/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - dense_2_accuracy: 0.3853 - dense_3_accuracy: 0.2225 - dense_4_accuracy: 0.3759 - loss: 4.7847 - val_dense_2_accuracy: 0.3523 - val_dense_3_accuracy: 0.2216 - val_dense_4_accuracy: 0.3352 - val_loss: 5.0883\n",
      "Epoch 97/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - dense_2_accuracy: 0.4090 - dense_3_accuracy: 0.2408 - dense_4_accuracy: 0.3701 - loss: 4.7689 - val_dense_2_accuracy: 0.3523 - val_dense_3_accuracy: 0.2358 - val_dense_4_accuracy: 0.3409 - val_loss: 5.1218\n",
      "Epoch 98/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - dense_2_accuracy: 0.4084 - dense_3_accuracy: 0.2451 - dense_4_accuracy: 0.3704 - loss: 4.8136 - val_dense_2_accuracy: 0.3494 - val_dense_3_accuracy: 0.2301 - val_dense_4_accuracy: 0.3210 - val_loss: 5.0961\n",
      "Epoch 99/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - dense_2_accuracy: 0.4018 - dense_3_accuracy: 0.2358 - dense_4_accuracy: 0.3460 - loss: 4.8368 - val_dense_2_accuracy: 0.3153 - val_dense_3_accuracy: 0.2358 - val_dense_4_accuracy: 0.3409 - val_loss: 5.0960\n",
      "Epoch 100/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - dense_2_accuracy: 0.3939 - dense_3_accuracy: 0.2322 - dense_4_accuracy: 0.3792 - loss: 4.7941 - val_dense_2_accuracy: 0.3523 - val_dense_3_accuracy: 0.2330 - val_dense_4_accuracy: 0.3409 - val_loss: 5.1025\n",
      "Epoch 101/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - dense_2_accuracy: 0.4116 - dense_3_accuracy: 0.2539 - dense_4_accuracy: 0.3378 - loss: 4.8580 - val_dense_2_accuracy: 0.3324 - val_dense_3_accuracy: 0.2301 - val_dense_4_accuracy: 0.3438 - val_loss: 5.1050\n",
      "Epoch 102/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - dense_2_accuracy: 0.3854 - dense_3_accuracy: 0.2230 - dense_4_accuracy: 0.3732 - loss: 4.7579 - val_dense_2_accuracy: 0.3494 - val_dense_3_accuracy: 0.2074 - val_dense_4_accuracy: 0.3409 - val_loss: 5.0826\n",
      "Epoch 103/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - dense_2_accuracy: 0.3955 - dense_3_accuracy: 0.2479 - dense_4_accuracy: 0.3650 - loss: 4.8294 - val_dense_2_accuracy: 0.3523 - val_dense_3_accuracy: 0.2330 - val_dense_4_accuracy: 0.3438 - val_loss: 5.0841\n",
      "Epoch 104/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - dense_2_accuracy: 0.4028 - dense_3_accuracy: 0.2411 - dense_4_accuracy: 0.3644 - loss: 4.7777 - val_dense_2_accuracy: 0.3523 - val_dense_3_accuracy: 0.2244 - val_dense_4_accuracy: 0.3352 - val_loss: 5.0870\n",
      "Epoch 105/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - dense_2_accuracy: 0.4016 - dense_3_accuracy: 0.1980 - dense_4_accuracy: 0.3489 - loss: 4.7869 - val_dense_2_accuracy: 0.3352 - val_dense_3_accuracy: 0.2358 - val_dense_4_accuracy: 0.3182 - val_loss: 5.0672\n",
      "Epoch 106/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - dense_2_accuracy: 0.4249 - dense_3_accuracy: 0.2161 - dense_4_accuracy: 0.3612 - loss: 4.8237 - val_dense_2_accuracy: 0.3381 - val_dense_3_accuracy: 0.2386 - val_dense_4_accuracy: 0.3438 - val_loss: 5.0807\n",
      "Epoch 107/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - dense_2_accuracy: 0.3996 - dense_3_accuracy: 0.2165 - dense_4_accuracy: 0.3529 - loss: 4.7476 - val_dense_2_accuracy: 0.3182 - val_dense_3_accuracy: 0.2301 - val_dense_4_accuracy: 0.3409 - val_loss: 5.1127\n",
      "Epoch 108/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - dense_2_accuracy: 0.3830 - dense_3_accuracy: 0.2239 - dense_4_accuracy: 0.3928 - loss: 4.7814 - val_dense_2_accuracy: 0.3494 - val_dense_3_accuracy: 0.2244 - val_dense_4_accuracy: 0.3182 - val_loss: 5.0786\n",
      "Epoch 109/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - dense_2_accuracy: 0.4075 - dense_3_accuracy: 0.2260 - dense_4_accuracy: 0.3455 - loss: 4.8417 - val_dense_2_accuracy: 0.3381 - val_dense_3_accuracy: 0.2330 - val_dense_4_accuracy: 0.3210 - val_loss: 5.0772\n",
      "Epoch 110/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.3933 - dense_3_accuracy: 0.2196 - dense_4_accuracy: 0.3595 - loss: 4.8101 - val_dense_2_accuracy: 0.3494 - val_dense_3_accuracy: 0.2386 - val_dense_4_accuracy: 0.3438 - val_loss: 5.0709\n",
      "Epoch 111/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 0.4061 - dense_3_accuracy: 0.2297 - dense_4_accuracy: 0.3688 - loss: 4.7598 - val_dense_2_accuracy: 0.3523 - val_dense_3_accuracy: 0.2358 - val_dense_4_accuracy: 0.3267 - val_loss: 5.0912\n",
      "Epoch 112/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - dense_2_accuracy: 0.4194 - dense_3_accuracy: 0.2096 - dense_4_accuracy: 0.3681 - loss: 4.8312 - val_dense_2_accuracy: 0.3494 - val_dense_3_accuracy: 0.2188 - val_dense_4_accuracy: 0.3438 - val_loss: 5.0758\n",
      "Epoch 113/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - dense_2_accuracy: 0.3358 - dense_3_accuracy: 0.2139 - dense_4_accuracy: 0.3847 - loss: 4.8253 - val_dense_2_accuracy: 0.3494 - val_dense_3_accuracy: 0.2273 - val_dense_4_accuracy: 0.3352 - val_loss: 5.1060\n",
      "Epoch 114/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - dense_2_accuracy: 0.4068 - dense_3_accuracy: 0.2271 - dense_4_accuracy: 0.3497 - loss: 4.8121 - val_dense_2_accuracy: 0.3409 - val_dense_3_accuracy: 0.2415 - val_dense_4_accuracy: 0.3352 - val_loss: 5.0699\n",
      "Epoch 115/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - dense_2_accuracy: 0.3937 - dense_3_accuracy: 0.2615 - dense_4_accuracy: 0.3707 - loss: 4.7805 - val_dense_2_accuracy: 0.3182 - val_dense_3_accuracy: 0.2415 - val_dense_4_accuracy: 0.3381 - val_loss: 5.0590\n",
      "Epoch 116/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - dense_2_accuracy: 0.4077 - dense_3_accuracy: 0.2382 - dense_4_accuracy: 0.3620 - loss: 4.7446 - val_dense_2_accuracy: 0.3523 - val_dense_3_accuracy: 0.2358 - val_dense_4_accuracy: 0.3097 - val_loss: 5.0710\n",
      "Epoch 117/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.3907 - dense_3_accuracy: 0.2275 - dense_4_accuracy: 0.3644 - loss: 4.7812 - val_dense_2_accuracy: 0.3097 - val_dense_3_accuracy: 0.2358 - val_dense_4_accuracy: 0.3239 - val_loss: 5.0415\n",
      "Epoch 118/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - dense_2_accuracy: 0.3736 - dense_3_accuracy: 0.2371 - dense_4_accuracy: 0.3518 - loss: 4.8346 - val_dense_2_accuracy: 0.3523 - val_dense_3_accuracy: 0.2358 - val_dense_4_accuracy: 0.3267 - val_loss: 5.0662\n",
      "Epoch 119/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.3854 - dense_3_accuracy: 0.2277 - dense_4_accuracy: 0.3725 - loss: 4.7095 - val_dense_2_accuracy: 0.3523 - val_dense_3_accuracy: 0.2415 - val_dense_4_accuracy: 0.3324 - val_loss: 5.0586\n",
      "Epoch 120/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.3961 - dense_3_accuracy: 0.2669 - dense_4_accuracy: 0.3485 - loss: 4.7672 - val_dense_2_accuracy: 0.3523 - val_dense_3_accuracy: 0.2273 - val_dense_4_accuracy: 0.3381 - val_loss: 5.0603\n",
      "Epoch 121/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.4061 - dense_3_accuracy: 0.2202 - dense_4_accuracy: 0.3793 - loss: 4.7909 - val_dense_2_accuracy: 0.3381 - val_dense_3_accuracy: 0.2415 - val_dense_4_accuracy: 0.3040 - val_loss: 5.0614\n",
      "Epoch 122/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - dense_2_accuracy: 0.3982 - dense_3_accuracy: 0.2314 - dense_4_accuracy: 0.3605 - loss: 4.7191 - val_dense_2_accuracy: 0.3381 - val_dense_3_accuracy: 0.2386 - val_dense_4_accuracy: 0.3097 - val_loss: 5.0592\n",
      "Epoch 123/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.3947 - dense_3_accuracy: 0.2286 - dense_4_accuracy: 0.3718 - loss: 4.8089 - val_dense_2_accuracy: 0.3523 - val_dense_3_accuracy: 0.2415 - val_dense_4_accuracy: 0.3267 - val_loss: 5.0629\n",
      "Epoch 124/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.3948 - dense_3_accuracy: 0.2379 - dense_4_accuracy: 0.3757 - loss: 4.6594 - val_dense_2_accuracy: 0.3523 - val_dense_3_accuracy: 0.2415 - val_dense_4_accuracy: 0.3125 - val_loss: 5.0541\n",
      "Epoch 125/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.3787 - dense_3_accuracy: 0.2317 - dense_4_accuracy: 0.3405 - loss: 4.8197 - val_dense_2_accuracy: 0.3494 - val_dense_3_accuracy: 0.2358 - val_dense_4_accuracy: 0.3381 - val_loss: 5.0610\n",
      "Epoch 126/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - dense_2_accuracy: 0.4100 - dense_3_accuracy: 0.2255 - dense_4_accuracy: 0.3678 - loss: 4.7306 - val_dense_2_accuracy: 0.3381 - val_dense_3_accuracy: 0.2330 - val_dense_4_accuracy: 0.3125 - val_loss: 5.0603\n",
      "Epoch 127/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - dense_2_accuracy: 0.4031 - dense_3_accuracy: 0.2307 - dense_4_accuracy: 0.3613 - loss: 4.7627 - val_dense_2_accuracy: 0.3494 - val_dense_3_accuracy: 0.2358 - val_dense_4_accuracy: 0.3409 - val_loss: 5.0362\n",
      "Epoch 128/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - dense_2_accuracy: 0.3894 - dense_3_accuracy: 0.2453 - dense_4_accuracy: 0.3436 - loss: 4.7924 - val_dense_2_accuracy: 0.3494 - val_dense_3_accuracy: 0.2102 - val_dense_4_accuracy: 0.3438 - val_loss: 5.0755\n",
      "Epoch 129/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - dense_2_accuracy: 0.4150 - dense_3_accuracy: 0.2452 - dense_4_accuracy: 0.3824 - loss: 4.7525 - val_dense_2_accuracy: 0.3523 - val_dense_3_accuracy: 0.2358 - val_dense_4_accuracy: 0.3438 - val_loss: 5.0317\n",
      "Epoch 130/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - dense_2_accuracy: 0.4154 - dense_3_accuracy: 0.2404 - dense_4_accuracy: 0.3949 - loss: 4.6812 - val_dense_2_accuracy: 0.3409 - val_dense_3_accuracy: 0.2330 - val_dense_4_accuracy: 0.3210 - val_loss: 5.0565\n",
      "Epoch 131/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - dense_2_accuracy: 0.3990 - dense_3_accuracy: 0.2301 - dense_4_accuracy: 0.3479 - loss: 4.7709 - val_dense_2_accuracy: 0.3352 - val_dense_3_accuracy: 0.2330 - val_dense_4_accuracy: 0.3438 - val_loss: 5.0636\n",
      "Epoch 132/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - dense_2_accuracy: 0.4046 - dense_3_accuracy: 0.2289 - dense_4_accuracy: 0.3601 - loss: 4.8123 - val_dense_2_accuracy: 0.3523 - val_dense_3_accuracy: 0.2358 - val_dense_4_accuracy: 0.3210 - val_loss: 5.0498\n",
      "Epoch 133/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.3989 - dense_3_accuracy: 0.2481 - dense_4_accuracy: 0.3627 - loss: 4.7923 - val_dense_2_accuracy: 0.3494 - val_dense_3_accuracy: 0.2330 - val_dense_4_accuracy: 0.2926 - val_loss: 5.0565\n",
      "Epoch 134/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.4048 - dense_3_accuracy: 0.2534 - dense_4_accuracy: 0.3437 - loss: 4.7212 - val_dense_2_accuracy: 0.3409 - val_dense_3_accuracy: 0.2386 - val_dense_4_accuracy: 0.3438 - val_loss: 5.0573\n",
      "Epoch 135/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.4053 - dense_3_accuracy: 0.2503 - dense_4_accuracy: 0.3716 - loss: 4.7284 - val_dense_2_accuracy: 0.3352 - val_dense_3_accuracy: 0.2330 - val_dense_4_accuracy: 0.3040 - val_loss: 5.0416\n",
      "Epoch 136/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.4299 - dense_3_accuracy: 0.2121 - dense_4_accuracy: 0.3624 - loss: 4.7890 - val_dense_2_accuracy: 0.3523 - val_dense_3_accuracy: 0.2330 - val_dense_4_accuracy: 0.3438 - val_loss: 5.0516\n",
      "Epoch 137/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.4103 - dense_3_accuracy: 0.2325 - dense_4_accuracy: 0.3628 - loss: 4.7655 - val_dense_2_accuracy: 0.3523 - val_dense_3_accuracy: 0.2386 - val_dense_4_accuracy: 0.3295 - val_loss: 5.0394\n",
      "Epoch 138/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.4054 - dense_3_accuracy: 0.2236 - dense_4_accuracy: 0.3557 - loss: 4.8432 - val_dense_2_accuracy: 0.3523 - val_dense_3_accuracy: 0.2330 - val_dense_4_accuracy: 0.3352 - val_loss: 5.0303\n",
      "Epoch 139/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - dense_2_accuracy: 0.3961 - dense_3_accuracy: 0.2497 - dense_4_accuracy: 0.3637 - loss: 4.7570 - val_dense_2_accuracy: 0.3494 - val_dense_3_accuracy: 0.2386 - val_dense_4_accuracy: 0.3352 - val_loss: 5.0265\n",
      "Epoch 140/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.4275 - dense_3_accuracy: 0.2465 - dense_4_accuracy: 0.3266 - loss: 4.7691 - val_dense_2_accuracy: 0.3665 - val_dense_3_accuracy: 0.2386 - val_dense_4_accuracy: 0.3097 - val_loss: 5.0222\n",
      "Epoch 141/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.4135 - dense_3_accuracy: 0.2241 - dense_4_accuracy: 0.3578 - loss: 4.7262 - val_dense_2_accuracy: 0.3352 - val_dense_3_accuracy: 0.2358 - val_dense_4_accuracy: 0.3438 - val_loss: 5.0206\n",
      "Epoch 142/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - dense_2_accuracy: 0.3917 - dense_3_accuracy: 0.2396 - dense_4_accuracy: 0.3700 - loss: 4.7557 - val_dense_2_accuracy: 0.3352 - val_dense_3_accuracy: 0.2045 - val_dense_4_accuracy: 0.3438 - val_loss: 5.0242\n",
      "Epoch 143/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - dense_2_accuracy: 0.4026 - dense_3_accuracy: 0.2003 - dense_4_accuracy: 0.3688 - loss: 4.7906 - val_dense_2_accuracy: 0.3409 - val_dense_3_accuracy: 0.2358 - val_dense_4_accuracy: 0.3210 - val_loss: 5.0526\n",
      "Epoch 144/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.3920 - dense_3_accuracy: 0.2337 - dense_4_accuracy: 0.3784 - loss: 4.7273 - val_dense_2_accuracy: 0.3523 - val_dense_3_accuracy: 0.2301 - val_dense_4_accuracy: 0.3381 - val_loss: 5.0324\n",
      "Epoch 145/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - dense_2_accuracy: 0.4010 - dense_3_accuracy: 0.2434 - dense_4_accuracy: 0.3822 - loss: 4.7633 - val_dense_2_accuracy: 0.3381 - val_dense_3_accuracy: 0.2415 - val_dense_4_accuracy: 0.3381 - val_loss: 5.0293\n",
      "Epoch 146/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - dense_2_accuracy: 0.3637 - dense_3_accuracy: 0.2446 - dense_4_accuracy: 0.3475 - loss: 4.7374 - val_dense_2_accuracy: 0.3324 - val_dense_3_accuracy: 0.2273 - val_dense_4_accuracy: 0.3324 - val_loss: 5.0613\n",
      "Epoch 147/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - dense_2_accuracy: 0.3945 - dense_3_accuracy: 0.2378 - dense_4_accuracy: 0.3624 - loss: 4.6999 - val_dense_2_accuracy: 0.3324 - val_dense_3_accuracy: 0.2386 - val_dense_4_accuracy: 0.3409 - val_loss: 5.0384\n",
      "Epoch 148/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - dense_2_accuracy: 0.4025 - dense_3_accuracy: 0.2228 - dense_4_accuracy: 0.3695 - loss: 4.7150 - val_dense_2_accuracy: 0.3267 - val_dense_3_accuracy: 0.2415 - val_dense_4_accuracy: 0.3182 - val_loss: 5.0240\n",
      "Epoch 149/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - dense_2_accuracy: 0.4168 - dense_3_accuracy: 0.2313 - dense_4_accuracy: 0.3639 - loss: 4.7335 - val_dense_2_accuracy: 0.3239 - val_dense_3_accuracy: 0.2386 - val_dense_4_accuracy: 0.3352 - val_loss: 5.0471\n",
      "Epoch 150/150\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - dense_2_accuracy: 0.3877 - dense_3_accuracy: 0.2379 - dense_4_accuracy: 0.3664 - loss: 4.7391 - val_dense_2_accuracy: 0.3494 - val_dense_3_accuracy: 0.2074 - val_dense_4_accuracy: 0.3182 - val_loss: 5.0401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Please consider providing the trackable_obj argument in the from_concrete_functions. Providing without the trackable_obj argument is deprecated and it will use the deprecated conversion path.\n",
      "C:\\Users\\h8888\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
      "Recommended places: ('National Zoological Park', 'Okhla Bird Sanctuary', 'Yamuna biodiversity Park')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_excel('sample_data.xlsx')\n",
    "\n",
    "# Initialize label encoders for categorical features and outputs\n",
    "label_encoders = {}\n",
    "for column in ['state', 'category', 'place1', 'place2', 'place3']:\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Normalize the rating column\n",
    "scaler = MinMaxScaler()\n",
    "data['rating'] = scaler.fit_transform(data[['rating']])\n",
    "\n",
    "# Separate features and outputs\n",
    "X = data[['state', 'category', 'rating']].values\n",
    "y1 = data['place1'].values\n",
    "y2 = data['place2'].values\n",
    "y3 = data['place3'].values\n",
    "\n",
    "# Convert outputs to one-hot encoding\n",
    "y1 = tf.keras.utils.to_categorical(y1, num_classes=len(label_encoders['place1'].classes_))\n",
    "y2 = tf.keras.utils.to_categorical(y2, num_classes=len(label_encoders['place2'].classes_))\n",
    "y3 = tf.keras.utils.to_categorical(y3, num_classes=len(label_encoders['place3'].classes_))\n",
    "\n",
    "# Input shape\n",
    "input_shape = X.shape[1]\n",
    "\n",
    "# Define the model\n",
    "input_layer = tf.keras.layers.Input(shape=(input_shape,))\n",
    "dense_layer = tf.keras.layers.Dense(64, activation='relu')(input_layer)\n",
    "dense_layer = tf.keras.layers.Dense(64, activation='relu')(dense_layer)\n",
    "\n",
    "# Output layers for place1, place2, and place3\n",
    "output1 = tf.keras.layers.Dense(len(label_encoders['place1'].classes_), activation='softmax')(dense_layer)\n",
    "output2 = tf.keras.layers.Dense(len(label_encoders['place2'].classes_), activation='softmax')(dense_layer)\n",
    "output3 = tf.keras.layers.Dense(len(label_encoders['place3'].classes_), activation='softmax')(dense_layer)\n",
    "\n",
    "# Create the model\n",
    "model = tf.keras.models.Model(inputs=input_layer, outputs=[output1, output2, output3])\n",
    "\n",
    "# Compile the model with separate metrics for each output\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy', 'accuracy', 'accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, [y1, y2, y3], epochs=150, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Save the model with .h5 extension\n",
    "model.save('my_model.h5')\n",
    "\n",
    "# Load the model back from the .h5 file\n",
    "loaded_model = tf.keras.models.load_model('my_model.h5')\n",
    "\n",
    "# Define the input signature\n",
    "input_signature = [tf.TensorSpec(shape=(None, input_shape), dtype=tf.float32)]\n",
    "\n",
    "# Create a concrete function from the Keras model\n",
    "concrete_func = tf.function(lambda x: loaded_model(x))\n",
    "concrete_func = concrete_func.get_concrete_function(input_signature)\n",
    "\n",
    "# Convert the loaded model to TensorFlow Lite format\n",
    "converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TensorFlow Lite model to a file\n",
    "with open('my_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "# Function to preprocess user input\n",
    "def preprocess_input(state, category, rating):\n",
    "    state_encoded = label_encoders['state'].transform([state])\n",
    "    category_encoded = label_encoders['category'].transform([category])\n",
    "    rating_normalized = scaler.transform([[rating]])\n",
    "    return np.array([state_encoded[0], category_encoded[0], rating_normalized[0][0]])\n",
    "\n",
    "# Function to predict and decode recommendations\n",
    "def recommend_places(state, category, rating):\n",
    "    input_data = preprocess_input(state, category, rating)\n",
    "    input_data = np.expand_dims(input_data, axis=0)\n",
    "    predictions = loaded_model.predict(input_data)\n",
    "    place1 = label_encoders['place1'].inverse_transform([np.argmax(predictions[0])])[0]\n",
    "    place2 = label_encoders['place2'].inverse_transform([np.argmax(predictions[1])])[0]\n",
    "    place3 = label_encoders['place3'].inverse_transform([np.argmax(predictions[2])])[0]\n",
    "    return place1, place2, place3\n",
    "\n",
    "# Example usage\n",
    "state = 'Delhi'\n",
    "category = 'Wildlife'\n",
    "rating = 4.5\n",
    "recommendations = recommend_places(state, category, rating)\n",
    "print(f'Recommended places: {recommendations}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f380713e-2081-49f6-b0c7-458e5e1a7b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding for state:\n",
      "Delhi -> 0\n",
      "Uttarakhand -> 1\n",
      "\n",
      "Encoding for category:\n",
      "Adventure sports -> 0\n",
      "Culture -> 1\n",
      "Entertainment -> 2\n",
      "Hill Station -> 3\n",
      "Historical -> 4\n",
      "Mall -> 5\n",
      "Market -> 6\n",
      "Museum -> 7\n",
      "Natural Beauty -> 8\n",
      "Religious -> 9\n",
      "Wildlife -> 10\n",
      "\n",
      "Encoding for place1:\n",
      "Akshardham Temple -> 0\n",
      "Ambience Mall -> 1\n",
      "Appu Ghar Express -> 2\n",
      "Askot Sanctuary -> 3\n",
      "Auli -> 4\n",
      "Badrinath -> 5\n",
      "Bangla Sahib Market -> 6\n",
      "Bhimtal lake -> 7\n",
      "Bhulla Lake -> 8\n",
      "Chakrata -> 9\n",
      "Chamoli -> 10\n",
      "Chandni Chowk -> 11\n",
      "Chhatarpur Temple -> 12\n",
      "Chopta -> 13\n",
      "Connaught Place -> 14\n",
      "Corbett National Park -> 15\n",
      "DLF CyberHub -> 16\n",
      "DLF Emporio -> 17\n",
      "Dehradun -> 18\n",
      "Delhi Haunted House -> 19\n",
      "Delhi Ridge Forest -> 20\n",
      "Dilli Haat INA -> 21\n",
      "Dronagiri -> 22\n",
      "Gandhi Smriti -> 23\n",
      "George Everest Peak -> 24\n",
      "Gurudwara Bangla Sahib -> 25\n",
      "Haldwani -> 26\n",
      "Haridwar -> 27\n",
      "Hauz Khas Village -> 28\n",
      "Humayun’s Tomb -> 29\n",
      "ISKCON Temple -> 30\n",
      "India Gate -> 31\n",
      "India Habitat Centre -> 32\n",
      "India International Centre -> 33\n",
      "Jageshwar -> 34\n",
      "Jama Masjid -> 35\n",
      "Janpath Market -> 36\n",
      "Jantar Mantar -> 37\n",
      "Joshimath -> 38\n",
      "Kafni Glacier -> 39\n",
      "Kainchi Dham -> 40\n",
      "Kausani -> 41\n",
      "Kedarnath -> 42\n",
      "Khari Baoli -> 43\n",
      "Lakshman Jhula -> 44\n",
      "Lansdowne -> 45\n",
      "Lotus Temple -> 46\n",
      "Madame Tussauds -> 47\n",
      "Mughal Gardens -> 48\n",
      "Mukteshwar -> 49\n",
      "Munsiyari -> 50\n",
      "Mussoorie -> 51\n",
      "Nag Tibba -> 52\n",
      "Nainital -> 53\n",
      "National Gallery of Modern Art -> 54\n",
      "National Museum -> 55\n",
      "National Zoological Park -> 56\n",
      "Neelkanth Mahadev Temple -> 57\n",
      "Neer Garh Waterfall -> 58\n",
      "Nizamuddin Dargah -> 59\n",
      "Palika Bazaar -> 60\n",
      "Panch Kedar -> 61\n",
      "Pauri -> 62\n",
      "Pindari Glacier -> 63\n",
      "Pithoragarh -> 64\n",
      "Purana Qila -> 65\n",
      "Qutub Minar -> 66\n",
      "Raj Ghat -> 67\n",
      "Rajaji Wildlife Sanctuary -> 68\n",
      "Rajouri Garden Market -> 69\n",
      "Rani Jheel -> 70\n",
      "Red Fort -> 71\n",
      "Roopkund -> 72\n",
      "Sacred Heart Cathedral -> 73\n",
      "Sahastradhara -> 74\n",
      "Sarojini Nagar Market -> 75\n",
      "Sattal -> 76\n",
      "Select Citywalk -> 77\n",
      "Talkatora Garden -> 78\n",
      "Tapovan -> 79\n",
      "Tehri -> 80\n",
      "Tughlaqabad Fort -> 81\n",
      "Valley of Flowers National Park -> 82\n",
      "\n",
      "Encoding for place2:\n",
      " Akshardham Temple -> 0\n",
      " Appu Ghar Express -> 1\n",
      " Badrinath -> 2\n",
      " Bangla Sahib Market -> 3\n",
      " Bhavishya Badri -> 4\n",
      " Bhimtal lake -> 5\n",
      " Bhulla Lake -> 6\n",
      " Binsar -> 7\n",
      " Chakrata -> 8\n",
      " Chamoli -> 9\n",
      " Chhatarpur Temple -> 10\n",
      " Connaught Place -> 11\n",
      " DLF Emporio -> 12\n",
      " Dehradun -> 13\n",
      " Delhi Ridge Biodiversity Park -> 14\n",
      " Delhi Ridge Forest -> 15\n",
      " Delhi-6 -> 16\n",
      " Devprayag -> 17\n",
      " Dhanaulti -> 18\n",
      " Dilli Haat INA -> 19\n",
      " Dronagiri -> 20\n",
      " Gangotri -> 21\n",
      " George Everest Peak -> 22\n",
      " Gomukh -> 23\n",
      " Gurudwara Bangla Sahib -> 24\n",
      " Hanuman Temple -> 25\n",
      " ISKCON Temple -> 26\n",
      " Jageshwar -> 27\n",
      " Janpath Market -> 28\n",
      " Jharipani Falls -> 29\n",
      " Kafni Glacier -> 30\n",
      " Kainchi Dham -> 31\n",
      " Kanatal -> 32\n",
      " Kedarnath -> 33\n",
      " Khan Market -> 34\n",
      " Khirsu -> 35\n",
      " Kingdom of Dreams -> 36\n",
      " Lakshman Jhula -> 37\n",
      " Lansdowne -> 38\n",
      " Laxminarayan Temple -> 39\n",
      " Mukteshwar -> 40\n",
      " Munsiyari -> 41\n",
      " Mussoorie -> 42\n",
      " Nag Tibba -> 43\n",
      " National Gallery of Modern Art -> 44\n",
      " National Rail Museum -> 45\n",
      " Neelkanth Mahadev Temple -> 46\n",
      " Neer Garh Waterfall -> 47\n",
      " Pacific Mall -> 48\n",
      " Palika Bazaar -> 49\n",
      " Panch Kedar -> 50\n",
      " Pangot And Kilbury Bird Sanctuary -> 51\n",
      " Pauri -> 52\n",
      " Pithoragarh -> 53\n",
      " Rajaji Wildlife Sanctuary -> 54\n",
      " Rajouri Garden Market -> 55\n",
      " Rani Jheel -> 56\n",
      " Ranikhet -> 57\n",
      " Roopkund -> 58\n",
      " Roorkee -> 59\n",
      " Sacred Heart Cathedral -> 60\n",
      " Sahastradhara -> 61\n",
      " Sarojini Nagar Market -> 62\n",
      " Sattal -> 63\n",
      " Select Citywalk -> 64\n",
      " St. James’ Church -> 65\n",
      " Talkatora Garden -> 66\n",
      " Tapovan -> 67\n",
      " Tungnath Temple -> 68\n",
      " Valley of Flowers National Park -> 69\n",
      "Art Spice Gallery -> 70\n",
      "Delhi Haunted House -> 71\n",
      "Feroz Shah Kotla Fort -> 72\n",
      "Fun N Food Village -> 73\n",
      "Humayun’s Tomb -> 74\n",
      "India Gate -> 75\n",
      "Lodi Art District -> 76\n",
      "Madame Tussauds -> 77\n",
      "Nehru Planetarium -> 78\n",
      "Okhla Bird Sanctuary -> 79\n",
      "Purana Qila -> 80\n",
      "Qutub Minar -> 81\n",
      "Raj Ghat -> 82\n",
      "Rashtrapati Bhavan -> 83\n",
      "Rishikesh -> 84\n",
      "Tughlaqabad Fort -> 85\n",
      "\n",
      "Encoding for place3:\n",
      "  Raj Ghat -> 0\n",
      " Almora -> 1\n",
      " Badrinath -> 2\n",
      " Bhavishya Badri -> 3\n",
      " Bhim Ghasutri -> 4\n",
      " Bhowali -> 5\n",
      " Bhulla Lake -> 6\n",
      " Binsar -> 7\n",
      " Binsar Wildlife Sanctuary -> 8\n",
      " Chakrata -> 9\n",
      " Chamoli -> 10\n",
      " Connaught Place -> 11\n",
      " Crafts Museum -> 12\n",
      " DLF Emporio -> 13\n",
      " Dayara Bugyal -> 14\n",
      " Delhi Ridge Biodiversity Park -> 15\n",
      " Delhi-6 -> 16\n",
      " Devprayag -> 17\n",
      " Dhanaulti -> 18\n",
      " Dharali -> 19\n",
      " Dronagiri -> 20\n",
      " Ganga Aarti at Triveni Ghat -> 21\n",
      " Gangotri -> 22\n",
      " Gomukh -> 23\n",
      " Greater Kailash M-Block Market -> 24\n",
      " Gurudwara Bangla Sahib -> 25\n",
      " Gurudwara Sis Ganj Sahib -> 26\n",
      " Gwaldam -> 27\n",
      " Hanuman Temple -> 28\n",
      " Hemkund Sahib -> 29\n",
      " ISKCON Temple -> 30\n",
      " Jageshwar -> 31\n",
      " Janpath Market -> 32\n",
      " Jhandewalan Temple -> 33\n",
      " Jharipani Falls -> 34\n",
      " Kafni Glacier -> 35\n",
      " Kainchi Dham -> 36\n",
      " Kanatal -> 37\n",
      " Karnaprayag -> 38\n",
      " Karol Bagh Market -> 39\n",
      " Kausani -> 40\n",
      " Kempty Falls -> 41\n",
      " Khan Market -> 42\n",
      " Khirsu -> 43\n",
      " Kingdom of Dreams -> 44\n",
      " Kunjapuri Temple -> 45\n",
      " Lakshman Jhula -> 46\n",
      " Lansdowne -> 47\n",
      " Laxminarayan Temple -> 48\n",
      " Lodhi Gardens -> 49\n",
      " Munsiyari -> 50\n",
      " Nag Tibba -> 51\n",
      " National Rail Museum -> 52\n",
      " Neer Garh Waterfall -> 53\n",
      " Pacific Mall -> 54\n",
      " Palika Bazaar -> 55\n",
      " Panch Kedar -> 56\n",
      " Pangot And Kilbury Bird Sanctuary -> 57\n",
      " Rajouri Garden Market -> 58\n",
      " Rani Jheel -> 59\n",
      " Roopkund -> 60\n",
      " Roorkee -> 61\n",
      " Sahastradhara -> 62\n",
      " Sarojini Nagar Market -> 63\n",
      " Satopanth Lake -> 64\n",
      " Sattal -> 65\n",
      " St. James’ Church -> 66\n",
      " St. Stephen’s Church -> 67\n",
      " Surkanda Devi Temple -> 68\n",
      " Swarg Ashram -> 69\n",
      " Talkatora Garden -> 70\n",
      " Tapkeshwar Temple -> 71\n",
      " Tapovan -> 72\n",
      " The Great India Place -> 73\n",
      " Tungnath Temple -> 74\n",
      " Vashishta Gufa -> 75\n",
      " Worlds of Wonder -> 76\n",
      "Adventure Island -> 77\n",
      "Agrasen ki Baoli -> 78\n",
      "Benog Wildlife Sanctuary -> 79\n",
      "Delhi Haunted House -> 80\n",
      "Delhi War Cemetery -> 81\n",
      "Feroz Shah Kotla Fort -> 82\n",
      "Fun N Food Village -> 83\n",
      "Gaumukh Glacier -> 84\n",
      "Kathputli Colony -> 85\n",
      "Purana Qila -> 86\n",
      "Qutub Minar -> 87\n",
      "Rashtrapati Bhavan -> 88\n",
      "Shankar’s International Dolls Museum -> 89\n",
      "Surajkund Mela -> 90\n",
      "Tughlaqabad Fort -> 91\n",
      "Yamuna biodiversity Park -> 92\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_excel('sample_data.xlsx')\n",
    "\n",
    "# Initialize label encoders for categorical features and outputs\n",
    "label_encoders = {}\n",
    "encoded_values = {}\n",
    "\n",
    "for column in ['state', 'category', 'place1', 'place2', 'place3']:\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "    label_encoders[column] = le\n",
    "    encoded_values[column] = le.classes_\n",
    "\n",
    "# Normalize the rating column\n",
    "scaler = MinMaxScaler()\n",
    "data['rating'] = scaler.fit_transform(data[['rating']])\n",
    "\n",
    "# Separate features and outputs\n",
    "X = data[['state', 'category', 'rating']].values\n",
    "y1 = data['place1'].values\n",
    "y2 = data['place2'].values\n",
    "y3 = data['place3'].values\n",
    "\n",
    "# Print the encoding numbers of all distinct categories\n",
    "for column in encoded_values:\n",
    "    print(f\"Encoding for {column}:\")\n",
    "    for idx, value in enumerate(encoded_values[column]):\n",
    "        print(f\"{value} -> {idx}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83dde192-bd29-419b-8960-6f611868ef59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "C:\\Users\\h8888\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] [9] <class 'numpy.ndarray'>\n",
      "1 9 <class 'numpy.float64'>\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step\n",
      "Type of predictions: <class 'list'>\n",
      "Length of predictions: 3\n",
      "Predictions: [array([[2.18224450e-04, 1.46623558e-08, 4.11087536e-15, 4.22247202e-11,\n",
      "        8.22213393e-18, 1.63017154e-01, 1.08422732e-07, 6.05930763e-05,\n",
      "        3.50890950e-05, 5.57536376e-04, 3.98355944e-08, 1.76552961e-09,\n",
      "        1.13450904e-12, 6.18832605e-03, 3.45844064e-09, 2.42803898e-03,\n",
      "        8.78306505e-15, 6.44992397e-08, 4.94163217e-08, 9.44858149e-24,\n",
      "        3.20166555e-13, 1.69184800e-09, 1.79656171e-12, 2.65577977e-08,\n",
      "        1.48694623e-09, 1.05811436e-04, 1.67736980e-09, 4.33491290e-01,\n",
      "        1.81560155e-23, 8.38707749e-12, 9.20159073e-05, 5.55895336e-13,\n",
      "        1.37933192e-29, 7.68839388e-22, 2.57644133e-05, 3.76329935e-13,\n",
      "        2.60887685e-08, 1.11007698e-12, 5.11212202e-05, 3.99538694e-05,\n",
      "        6.51796436e-05, 9.06460613e-08, 3.26277852e-01, 1.59913629e-08,\n",
      "        1.41332393e-05, 6.88186503e-08, 3.02334753e-04, 2.73685509e-23,\n",
      "        5.91359101e-14, 3.65299613e-08, 2.63427477e-03, 7.16391426e-08,\n",
      "        4.09982881e-10, 9.78138104e-08, 2.95405193e-12, 2.36146253e-13,\n",
      "        2.53548751e-06, 2.22506987e-05, 4.06219919e-11, 1.27991065e-04,\n",
      "        9.71825198e-09, 5.91564588e-02, 3.93953581e-09, 2.01975060e-13,\n",
      "        3.45509363e-08, 8.56937134e-14, 2.45773481e-13, 2.59434502e-10,\n",
      "        8.95161356e-04, 2.96149172e-09, 3.40250554e-05, 1.47718088e-11,\n",
      "        5.14142339e-05, 1.47332845e-04, 9.82605219e-10, 1.02969082e-07,\n",
      "        4.94325141e-05, 2.34946739e-07, 2.75646232e-13, 7.24707133e-05,\n",
      "        7.39355237e-05, 1.62870856e-12, 3.76117625e-03]], dtype=float32), array([[1.1984333e-04, 6.7667959e-15, 2.4410985e-01, 2.5994142e-08,\n",
      "        4.9893424e-05, 7.1738075e-05, 3.2218282e-05, 6.7534280e-08,\n",
      "        6.4835112e-05, 3.8352237e-08, 3.5440500e-12, 1.9057660e-08,\n",
      "        9.7516292e-08, 2.0017486e-08, 1.3564801e-12, 6.7135268e-13,\n",
      "        1.0035865e-08, 7.9111567e-05, 8.0414040e-09, 3.1194678e-09,\n",
      "        1.5456157e-09, 1.0075174e-04, 7.4148382e-11, 3.1277018e-03,\n",
      "        1.9739821e-04, 4.9086147e-12, 1.3368162e-04, 6.1095670e-05,\n",
      "        2.5536041e-08, 2.1596360e-11, 4.0986411e-05, 7.4980373e-05,\n",
      "        1.6798065e-08, 2.3733757e-01, 5.3487454e-09, 2.7188044e-05,\n",
      "        1.9624674e-18, 7.4483905e-05, 3.5479932e-08, 1.8533766e-04,\n",
      "        7.5052551e-09, 4.0194546e-03, 8.4752578e-09, 5.1473615e-13,\n",
      "        2.3869549e-11, 3.9445287e-12, 6.2212748e-05, 4.3629987e-12,\n",
      "        8.2307615e-08, 2.6499938e-09, 3.1914714e-01, 1.6458931e-03,\n",
      "        7.1551751e-09, 1.4531837e-11, 1.1595486e-03, 1.7069496e-08,\n",
      "        5.5963741e-05, 3.2081704e-08, 6.0960181e-05, 4.8824957e-09,\n",
      "        1.9866733e-04, 7.1954508e-13, 2.5908312e-08, 6.6139655e-05,\n",
      "        1.1071034e-07, 1.8974477e-04, 9.1686066e-13, 5.7412526e-05,\n",
      "        1.8196495e-01, 5.4779965e-03, 4.4193598e-22, 5.1060737e-22,\n",
      "        1.7434837e-12, 3.2536776e-21, 5.0790379e-12, 1.0054889e-12,\n",
      "        4.8821211e-25, 8.2982532e-23, 2.5907818e-08, 4.5227921e-06,\n",
      "        3.8569039e-12, 6.8682527e-13, 2.7454072e-12, 3.7696001e-12,\n",
      "        1.3954959e-16, 5.7858774e-13]], dtype=float32), array([[1.94825493e-11, 7.78554465e-08, 6.15897141e-02, 3.43646352e-05,\n",
      "        2.88176325e-05, 4.93715555e-11, 4.16904877e-05, 4.47465389e-08,\n",
      "        1.53673941e-03, 5.09622798e-04, 2.28060451e-08, 1.83502529e-08,\n",
      "        1.50448867e-13, 5.19129308e-08, 2.94123929e-05, 8.15064026e-14,\n",
      "        3.37584716e-09, 5.72177260e-06, 1.25284899e-07, 3.02192602e-05,\n",
      "        1.59514346e-11, 2.64859355e-05, 2.88290667e-05, 4.46665799e-03,\n",
      "        1.98453920e-09, 1.09495602e-04, 2.10554892e-04, 1.00142017e-07,\n",
      "        2.32535779e-13, 4.75165516e-01, 1.19040349e-04, 3.70597154e-05,\n",
      "        3.62878771e-09, 5.24643534e-13, 4.56150881e-11, 4.09090426e-05,\n",
      "        4.54715082e-05, 7.66451933e-08, 1.12190774e-05, 3.78704845e-09,\n",
      "        3.69916187e-08, 6.69189183e-12, 6.08554274e-09, 3.61546445e-05,\n",
      "        5.78856228e-17, 2.80111108e-05, 4.59498078e-05, 2.90233668e-08,\n",
      "        1.17184412e-04, 1.25159716e-13, 2.10540718e-03, 1.18668825e-11,\n",
      "        1.23942534e-12, 3.99327273e-13, 6.43208722e-08, 1.89999172e-09,\n",
      "        1.28082305e-01, 8.49237316e-04, 4.36437331e-09, 2.00835402e-05,\n",
      "        3.67011744e-05, 2.56406202e-10, 4.70185479e-12, 6.53685661e-10,\n",
      "        7.14617921e-03, 2.12776467e-05, 1.70924162e-04, 1.43695564e-04,\n",
      "        3.52818097e-05, 9.26262237e-06, 1.47322963e-13, 2.77244835e-05,\n",
      "        1.10933215e-05, 1.66720895e-08, 3.16993117e-01, 5.06288270e-05,\n",
      "        2.17766665e-16, 1.11504378e-22, 3.37239264e-12, 1.99904589e-11,\n",
      "        2.03125668e-24, 1.23545475e-13, 2.20195210e-14, 9.68023247e-25,\n",
      "        6.05676068e-19, 8.23284399e-28, 4.28845680e-13, 3.01649493e-13,\n",
      "        5.93259870e-13, 5.84902580e-08, 6.87885336e-20, 2.79788047e-13,\n",
      "        1.37908535e-06]], dtype=float32)]\n",
      "Shape of predictions[0]: (1, 83)\n",
      "Shape of predictions[1]: (1, 86)\n",
      "Shape of predictions[2]: (1, 93)\n",
      "Recommended places: ('Haridwar', ' Panch Kedar', ' Hemkund Sahib')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "loaded_model = tf.keras.models.load_model('my_model.h5')\n",
    "\n",
    "def preprocess_input(state, category, rating):\n",
    "    state_encoded = label_encoders['state'].transform([state])\n",
    "    category_encoded = label_encoders['category'].transform([category])\n",
    "    rating_normalized = scaler.transform([[rating]])\n",
    "    print( state_encoded, category_encoded, type(rating_normalized))\n",
    "    print( state_encoded[0], category_encoded[0], type(rating_normalized[0][0]))\n",
    "    return np.array([state_encoded[0], category_encoded[0], rating_normalized[0][0]])\n",
    "\n",
    "# Function to predict and decode recommendations\n",
    "def recommend_places(state, category, rating):\n",
    "    input_data = preprocess_input(state, category, rating)\n",
    "    input_data = np.expand_dims(input_data, axis=0)\n",
    "    predictions = loaded_model.predict(input_data)\n",
    "    print(\"Type of predictions:\", type(predictions))\n",
    "    print(\"Length of predictions:\", len(predictions))\n",
    "    print(\"Predictions:\", predictions)\n",
    "    \n",
    "    # Assuming predictions is a list of arrays, print the shape of each array\n",
    "    for i, pred in enumerate(predictions):\n",
    "        print(f\"Shape of predictions[{i}]:\", pred.shape)\n",
    "    place1 = label_encoders['place1'].inverse_transform([np.argmax(predictions[0])])[0]\n",
    "    place2 = label_encoders['place2'].inverse_transform([np.argmax(predictions[1])])[0]\n",
    "    place3 = label_encoders['place3'].inverse_transform([np.argmax(predictions[2])])[0]\n",
    "    return place1, place2, place3\n",
    "\n",
    "# Example usage\n",
    "state = 'Uttarakhand'\n",
    "category = 'Religious'\n",
    "rating = 4.5\n",
    "recommendations = recommend_places(state, category, rating)\n",
    "print(f'Recommended places: {recommendations}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc088f5a-6a74-4543-af50-27c04867a30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "1751    1\n",
      "1752    1\n",
      "1753    1\n",
      "1754    1\n",
      "1755    1\n",
      "Name: state, Length: 1756, dtype: int32\n",
      "0        1\n",
      "1        1\n",
      "2        2\n",
      "3        2\n",
      "4        2\n",
      "        ..\n",
      "1751    11\n",
      "1752    11\n",
      "1753    11\n",
      "1754    11\n",
      "1755    11\n",
      "Name: category, Length: 1756, dtype: int32\n",
      "0       33\n",
      "1       32\n",
      "2       16\n",
      "3       16\n",
      "4       16\n",
      "        ..\n",
      "1751    15\n",
      "1752    15\n",
      "1753    15\n",
      "1754    68\n",
      "1755     3\n",
      "Name: place1, Length: 1756, dtype: int32\n",
      "0       70\n",
      "1       76\n",
      "2        1\n",
      "3        1\n",
      "4       36\n",
      "        ..\n",
      "1751    54\n",
      "1752    54\n",
      "1753    51\n",
      "1754    51\n",
      "1755    53\n",
      "Name: place2, Length: 1756, dtype: int32\n",
      "0       90\n",
      "1       85\n",
      "2       44\n",
      "3       76\n",
      "4       76\n",
      "        ..\n",
      "1751    57\n",
      "1752     8\n",
      "1753     8\n",
      "1754     8\n",
      "1755    79\n",
      "Name: place3, Length: 1756, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_excel('sample_data.xlsx')\n",
    "\n",
    "# Initialize label encoders for categorical features and outputs\n",
    "label_encoders = {}\n",
    "for column in ['state', 'category', 'place1', 'place2', 'place3']:\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "    label_encoders[column] = le\n",
    "    print(data[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8bc99e-d580-45d4-9934-2ace45e5e762",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
